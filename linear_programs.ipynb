{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "import networkx as nx\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(G):\n",
    "    nx_G = nx.from_dict_of_lists(G)\n",
    "    nx.draw_networkx(nx_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Program for fractional clique number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to return all possible subsests for list of vertices V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets(V, prefix=[], arr_sets=[]):\n",
    "    if V == []: return\n",
    "    for i in range(len(V)):\n",
    "        subset = prefix + [V[i]]\n",
    "        arr_sets += [subset]\n",
    "        subsets(V[i+1:], subset, arr_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clique(graph, v_set):\n",
    "    if len(v_set) < 2: return True\n",
    "    for i in range(len(v_set)):\n",
    "        i_set = set(v_set[:i] + v_set[i+1:])\n",
    "        g_set = graph[v_set[i]]\n",
    "        if i_set & g_set != i_set :\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_clique_set(graph, v_encode, subsets, A=[]):\n",
    "    for subset in subsets:\n",
    "        if check_clique(graph, subset):\n",
    "            A += [sum([v_encode[v] for v in subset])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_clique(graph):\n",
    "    V = list(graph.keys())\n",
    "    v_encode = {}\n",
    "    v_num = len(V)\n",
    "    \n",
    "    for i in range(v_num):\n",
    "        temp = np.zeros(v_num)\n",
    "        temp[i] = -1\n",
    "        v_encode[V[i]] = temp\n",
    "    \n",
    "    arr_sets = []\n",
    "    subsets(V, arr_sets=arr_sets)\n",
    "    \n",
    "    b_clique = np.negative(np.ones(v_num))\n",
    "    A_clique = []\n",
    "    A_clique_set(graph, v_encode, arr_sets,A=A_clique)\n",
    "    A_clique = np.transpose(np.array(A_clique))\n",
    "    c_clique = np.ones(A_clique.shape[1])\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_clique, b_ub=b_clique, bounds=(0, None))\n",
    "    return res, A_clique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Program for Shannon entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unconnected_v(graph):\n",
    "    keys = list(graph.keys())\n",
    "    for v in keys:\n",
    "        if len(graph[v]) == 0:\n",
    "            graph.pop(v, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "G10 = {1:set({}), 2:set({}), 3:set({}), 4:set({}), 5:set({}), 6:set({})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unconnected_v(G10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets_dict(V, prefix=[], arr_sets={}):\n",
    "    if V == []: return 1\n",
    "    for i in range(len(V)):\n",
    "        subset = prefix + [V[i]]\n",
    "        arr_sets[tuple(subset)] = len(arr_sets)\n",
    "        subsets_dict(V[i+1:], subset, arr_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for subset in subsets_dict:\n",
    "        subset_len = len(subset)\n",
    "        subset_i = subsets_dict[subset]\n",
    "        a_lq = np.zeros(num_sets)\n",
    "        if subset_len > 1:\n",
    "            a_lq[subset_i] = -1 * (subset_len)\n",
    "            a_mq = np.zeros(num_sets)\n",
    "            a_mq[subset_i] = subset_len - 1\n",
    "            s = set(subset)\n",
    "            for v in subset:\n",
    "                sub_i = subsets_dict[tuple(x for x in subset if v != x)]\n",
    "                a_lq[sub_i] = 1    \n",
    "                a_mq[sub_i] = -1\n",
    "            A += [a_lq, a_mq]\n",
    "            b += [0, 0]\n",
    "        else:\n",
    "            a_lq[subset_i] = 1\n",
    "            A += [a_lq]\n",
    "            b += [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_2(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        for j in range(i, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            a_lq = np.zeros(num_sets)\n",
    "            if len(subset_i) < 2 and pos_i == pos_j: \n",
    "                a_lq[pos_i] = 1\n",
    "                A += [a_lq]\n",
    "                b += [1]\n",
    "#                 print(\"identical\", subset_i)\n",
    "            else:\n",
    "                a_mq = np.zeros(num_sets)\n",
    "                subset_i = set(subset_i)\n",
    "                subset_j = set(subset_j)\n",
    "                subset_ij_u = subset_i | subset_j\n",
    "                subset_ij_i = subset_i & subset_j\n",
    "                if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                    if len(subset_i) > len(subset_j):\n",
    "                        a_mq[pos_i] = -1\n",
    "                        a_mq[pos_j] = 1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    elif len(subset_i) < len(subset_j):\n",
    "                        a_mq[pos_i] = 1\n",
    "                        a_mq[pos_j] = -1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "#                     print(\"intersect each other\", subset_i, subset_j)\n",
    "                else:\n",
    "#                     print(\"not intersection of each other\", subset_i, subset_j)\n",
    "                    a_lq[pos_i] = -1\n",
    "                    a_lq[pos_j] = -1\n",
    "                    a_lq[subsets_dict[tuple(subset_ij_u)]] = 1\n",
    "                    if len(subset_ij_i) > 0:\n",
    "                        a_lq[subsets_dict[tuple(subset_ij_i)]] = 1\n",
    "                    A += [a_lq]\n",
    "                    b += [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version is missing a lot of important conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_3(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        for j in range(i, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            a_mq = np.zeros(num_sets)\n",
    "            if len(subset_i) < 2 and pos_i == pos_j: \n",
    "                a_mq[pos_i] = 1\n",
    "                A += [a_mq]\n",
    "                b += [1]\n",
    "            else:\n",
    "                subset_i = set(subset_i)\n",
    "                subset_j = set(subset_j)\n",
    "                subset_ij_u = subset_i | subset_j\n",
    "                subset_ij_i = subset_i & subset_j\n",
    "                if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                    if len(subset_i) > len(subset_j):\n",
    "                        a_mq[pos_i] = -1\n",
    "                        a_mq[pos_j] = 1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    elif len(subset_i) < len(subset_j):\n",
    "                        a_mq[pos_i] = 1\n",
    "                        a_mq[pos_j] = -1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "        \n",
    "        if len(subset_i) > 1:\n",
    "            a_lq = np.zeros(num_sets)\n",
    "            a_lq[pos_i] = 1\n",
    "            for v in subset_i:\n",
    "                sub_i = subsets_dict[(v,)]\n",
    "                a_lq[sub_i] = -1\n",
    "            A += [a_lq]\n",
    "            b += [0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_eq_dict(graph, eq_dict={}):\n",
    "    for v in graph:\n",
    "        n = tuple(graph[v])\n",
    "        n_v = tuple(graph[v] | {v})\n",
    "        if n in eq_dict:\n",
    "            eq_dict[n_v] = eq_dict[n]\n",
    "        else:\n",
    "            eq_dict[n] = n_v    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_4(graph, subsets_dict, eq_dict,  A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        rep_i = subset_i in eq_dict\n",
    "        if len(subset_i) < 2: \n",
    "            a_mq = np.zeros(num_sets)\n",
    "            a_mq[pos_i] = 1\n",
    "            A += [a_mq]\n",
    "            b += [1]\n",
    "        for j in range(i + 1, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            rep_j = subset_j in eq_dict            \n",
    "            \n",
    "            if rep_i:\n",
    "                pos_i = subsets_dict[eq_dict[subset_i]]\n",
    "                val_i = eq_dict[subset_i]\n",
    "            if rep_j:\n",
    "                pos_j = subsets_dict[eq_dict[subset_j]]\n",
    "                val_j = eq_dict[subset_j]\n",
    "\n",
    "            subset_i_s = set(subset_i)\n",
    "            subset_j_s = set(subset_j)\n",
    "            subset_ij_u = tuple(subset_i_s | subset_j_s)\n",
    "            subset_ij_i = tuple(subset_i_s & subset_j_s)\n",
    "                \n",
    "            if ((pos_i == pos_j) or\n",
    "                (rep_i and (val_i == subset_j or val_i == subset_ij_u)) or\n",
    "                (rep_j and (val_j == subset_i or val_j == subset_ij_u)) or \n",
    "                (rep_i and rep_j and val_i == val_j)):\n",
    "                continue\n",
    "            \n",
    "            if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                diff = len(subset_i) - len(subset_j)\n",
    "                a_mq = np.zeros(num_sets) \n",
    "                if diff == 1:\n",
    "                    a_mq[pos_i] = -1\n",
    "                    a_mq[pos_j] = 1\n",
    "                    A += [a_mq]\n",
    "                    b += [0]\n",
    "                elif diff == -1:\n",
    "                    a_mq[pos_i] = 1\n",
    "                    a_mq[pos_j] = -1\n",
    "                    A += [a_mq]\n",
    "                    b += [0]\n",
    "            else:\n",
    "                a_lq = np.zeros(num_sets) \n",
    "                a_lq[pos_i] = -1\n",
    "                a_lq[pos_j] = -1\n",
    "                a_lq[subsets_dict[subset_ij_u]] = 1\n",
    "                if len(subset_ij_i) > 0:\n",
    "                    a_lq[subsets_dict[subset_ij_i]] = 1\n",
    "                A += [a_lq]\n",
    "                b += [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_eq_set(graph, subsets_dict, A=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for v in graph:\n",
    "        n = tuple(graph[v])\n",
    "        n_v = tuple(graph[v] | {v})\n",
    "        a_eq = np.zeros(num_sets)\n",
    "        a_eq[subsets_dict[n_v]] = 1\n",
    "        if len(n) > 0: \n",
    "            a_eq[subsets_dict[n]] = -1\n",
    "        A += [a_eq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_eq_set_2(subsets_dict, eq_dict, A=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for k in eq_dict:\n",
    "        v = eq_dict[k]\n",
    "        a_eq = np.zeros(num_sets)\n",
    "        a_eq[subsets_dict[k]] = 1\n",
    "        a_eq[subsets_dict[v]] = -1\n",
    "        A += [a_eq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_A(A=[]):\n",
    "    a = np.ascontiguousarray(A)\n",
    "    unique_a = np.unique(a.view([('', a.dtype)]*a.shape[1]))\n",
    "    A = unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_entropy_1(graph):\n",
    "    # remove all isolated vertices from the graph\n",
    "    removed_unconnected_v(graph)\n",
    "        \n",
    "    V = list(graph.keys())\n",
    "    v_num = len(V)\n",
    "    \n",
    "    if v_num == 0: return 0\n",
    "    \n",
    "    arr_sets = {}\n",
    "    subsets_dict(V, arr_sets=arr_sets)\n",
    "    \n",
    "    eq_dict = {}\n",
    "    entropy_eq_dict(graph, eq_dict=eq_dict)\n",
    "    \n",
    "    A_entropy = []\n",
    "    b_entropy = []\n",
    "    A_entropy_set_2(graph, arr_sets, A=A_entropy, b=b_entropy)\n",
    "    A_entropy = np.array(A_entropy)\n",
    "    b_entropy = np.array(b_entropy, dtype=float)\n",
    "    \n",
    "    A_entropy_eq = []\n",
    "    A_entropy_eq_set(graph, arr_sets, A=A_entropy_eq)\n",
    "    A_entropy_eq = np.array(A_entropy_eq)\n",
    "    b_entropy_eq = np.zeros(A_entropy_eq.shape[0])\n",
    "    \n",
    "    c_clique = np.zeros(len(arr_sets))\n",
    "    c_clique[arr_sets[tuple(V)]] = -1\n",
    "    \n",
    "    print(A_entropy, A_entropy.shape)\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_entropy, b_ub=b_entropy, A_eq=A_entropy_eq, b_eq=b_entropy_eq, bounds=(0, None))\n",
    "    \n",
    "    x = res.x\n",
    "    keys = list(arr_sets.keys())\n",
    "    for i in range(x.shape[0]):\n",
    "        print(keys[i], x[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_entropy(graph):\n",
    "    # remove all isolated vertices from the graph\n",
    "    remove_unconnected_v(graph)\n",
    "        \n",
    "    V = list(graph.keys())\n",
    "    v_num = len(V)\n",
    "    \n",
    "    if v_num == 0: return 0\n",
    "    \n",
    "    arr_sets = {}\n",
    "    subsets_dict(V, arr_sets=arr_sets)\n",
    "    \n",
    "    eq_dict = {}\n",
    "    entropy_eq_dict(graph, eq_dict=eq_dict)\n",
    "    \n",
    "    print(eq_dict)\n",
    "    \n",
    "    A_entropy = []\n",
    "    A_entropy_set_4(graph, arr_sets, eq_dict, A=A_entropy)\n",
    "    A_entropy = np.array(A_entropy)\n",
    "    remove_duplicate_A(A=A_entropy)\n",
    "    b_entropy = np.zeros(A_entropy.shape[0])\n",
    "    add_v_Ab(V, arr_sets, A=A_entropy, b=b_entropy)\n",
    "    \n",
    "    A_entropy_eq = []\n",
    "    A_entropy_eq_set_2(arr_sets, eq_dict, A=A_entropy_eq)\n",
    "    A_entropy_eq = np.array(A_entropy_eq)\n",
    "    b_entropy_eq = np.zeros(A_entropy_eq.shape[0])\n",
    "    \n",
    "    c_clique = np.zeros(len(arr_sets))\n",
    "    c_clique[arr_sets[tuple(V)]] = -1\n",
    "    \n",
    "    print(A_entropy, A_entropy.shape)\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_entropy, b_ub=b_entropy, A_eq=A_entropy_eq, b_eq=b_entropy_eq, bounds=(0, None))\n",
    "    \n",
    "    x = res.x\n",
    "    keys = list(arr_sets.keys())\n",
    "    for i in range(x.shape[0]):\n",
    "        print(keys[i], x[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = {1:{2,5,6}, 2:{1,3,6}, 3:{2,4}, 4:{3,5,7}, 5:{1,4}, 6:{1,2,7}, 7:{4,6}}\n",
    "G2 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4,6}, 4:{3,5}, 5:{1,4}, 6:{1,3,7}, 7:{2,6}}\n",
    "G3 = {1:{2,5,6}, 2:{1,3}, 3:{2,4,6}, 4:{3,5,7}, 5:{1,4}, 6:{1,3,7}, 7:{4,6}}\n",
    "G4 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4,6}, 4:{3,5,7}, 5:{1,4}, 6:{1,3,7}, 7:{2,4,6}}\n",
    "G5 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4}, 4:{3,5}, 5:{1,4}, 6:{1,7}, 7:{2,6}}\n",
    "G6 = {1:{2,5,6}, 2:{1,3}, 3:{2,4,7}, 4:{3,5}, 5:{1,4}, 6:{1,7}, 7:{3,6}}\n",
    "G7 = {1:{2,3,4,5,6,7}, 2:{1,3,4,5,6,7}, 3:{1,2,4,5,6,7}, 4:{1,2,3,5,6,7}, 5:{1,2,3,4,6,7}, 6:{1,2,3,4,5,7}, 7:{1,2,3,4,5,6}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "G8 = {1:{2,5}, 2:{1,3}, 3:{2,4}, 4:{3,5}, 5:{1,4}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "G9 = {1:{2,6}, 2:{1,3}, 3:{2,4}, 4:{3,5}, 5:{4,6}, 6:{1,5}}\n",
    "G10 = {1:{2}, 2:{1}, 3:set({}), 4:set({}), 5:set({}), 6:set({})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "G11 = {1:{3,4}, 2:{3,4}, 3:{1,2}, 4: {1,2}}\n",
    "draw_graph(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(3, 4): (1, 3, 4), (2, 3, 4): (1, 3, 4), (1, 2): (1, 2, 3), (1, 2, 4): (1, 2, 3)}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'b' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-390f7053654e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlp_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-8a35a66c8ecb>\u001b[0m in \u001b[0;36mlp_entropy\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mA_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mA_entropy_set_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mA_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mremove_duplicate_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-0205c03d3619>\u001b[0m in \u001b[0;36mA_entropy_set_4\u001b[0;34m(graph, subsets_dict, eq_dict, A)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0ma_mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma_mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msubset_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'b' referenced before assignment"
     ]
    }
   ],
   "source": [
    "lp_entropy(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (109, 15)\n",
      "(1,) 1.0\n",
      "(1, 2) 2.0\n",
      "(1, 2, 3) 2.0\n",
      "(1, 2, 3, 4) 2.0\n",
      "(1, 2, 4) 2.0\n",
      "(1, 3) 1.0\n",
      "(1, 3, 4) 2.0\n",
      "(1, 4) 2.0\n",
      "(2,) 1.0\n",
      "(2, 3) 2.0\n",
      "(2, 3, 4) 2.0\n",
      "(2, 4) 1.0\n",
      "(3,) 1.0\n",
      "(3, 4) 2.0\n",
      "(4,) 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     con: array([0., 0., 0., 0.])\n",
       "     fun: -2.0\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 153\n",
       "   slack: array([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 1., 2., 1., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 2., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0.])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1., 2., 2., 2., 2., 1., 2., 2., 1., 2., 2., 1., 1., 2., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_entropy_1(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G11 = {1:{2,3,4,5}, 2:{1,3}, 3:{1,2}, 4: {1,5}, 5:{1,4}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_entropy(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.optimize.show_options('linprog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1., 2., 2., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 2., 2., 2., 1.,\n",
    "       2., 3., 3., 3., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_approx_identical_entropy(G1, G2):\n",
    "    entropy_g1 = lp_entropy(G1)\n",
    "    entropy_g2 = lp_entropy(G2)\n",
    "    print(np.round(entropy_g1.x))\n",
    "    print(np.round(entropy_g2.x))\n",
    "    return np.array_equal(np.round(entropy_g1.x), np.round(entropy_g2.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = {1:{2,3,4,5}, 2:{1,3}, 3:{1,2}, 4: {1,5}, 5:{1,4}}\n",
    "draw_graph(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = {1:{2,3,4,5}, 2:{1,3,4}, 3:{1,2}, 4: {1,2,5}, 5:{1,4}}\n",
    "draw_graph(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = {1:{2,3,4,5}, 2:{1,3,4}, 3:{1,2,4}, 4: {1,2,3,5}, 5:{1,4}}\n",
    "draw_graph(G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G4 = {1:{2,3,4,5}, 2:{1,3,4}, 3:{1,2,5}, 4: {1,2,5}, 5:{1,3,4}}\n",
    "draw_graph(G4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G5 = {1:{2,4,5}, 2:{1,3,4}, 3:{2,5}, 4: {1,2,5}, 5:{1,3,4}}\n",
    "draw_graph(G5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G6 = {1:{2,3,5}, 2:{1,3,4}, 3:{1,2,5}, 4: {2,5}, 5:{1,3,4}}\n",
    "draw_graph(G6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_approx_identical_entropy(G5,G4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
