{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "import networkx as nx\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(G):\n",
    "    nx_G = nx.from_dict_of_lists(G)\n",
    "    nx.draw_networkx(nx_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Program for fractional clique number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to return all possible subsests for list of vertices V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets(V, prefix=[], arr_sets=[]):\n",
    "    if V == []: return\n",
    "    for i in range(len(V)):\n",
    "        subset = prefix + [V[i]]\n",
    "        arr_sets += [subset]\n",
    "        subsets(V[i+1:], subset, arr_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clique(graph, v_set):\n",
    "    if len(v_set) < 2: return True\n",
    "    for i in range(len(v_set)):\n",
    "        i_set = set(v_set[:i] + v_set[i+1:])\n",
    "        g_set = graph[v_set[i]]\n",
    "        if i_set & g_set != i_set :\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_clique_set(graph, v_encode, subsets, A=[]):\n",
    "    for subset in subsets:\n",
    "        if check_clique(graph, subset):\n",
    "            A += [sum([v_encode[v] for v in subset])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_clique(graph):\n",
    "    V = list(graph.keys())\n",
    "    v_encode = {}\n",
    "    v_num = len(V)\n",
    "    \n",
    "    for i in range(v_num):\n",
    "        temp = np.zeros(v_num)\n",
    "        temp[i] = -1\n",
    "        v_encode[V[i]] = temp\n",
    "    \n",
    "    arr_sets = []\n",
    "    subsets(V, arr_sets=arr_sets)\n",
    "    \n",
    "    b_clique = np.negative(np.ones(v_num))\n",
    "    A_clique = []\n",
    "    A_clique_set(graph, v_encode, arr_sets,A=A_clique)\n",
    "    A_clique = np.transpose(np.array(A_clique))\n",
    "    c_clique = np.ones(A_clique.shape[1])\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_clique, b_ub=b_clique, bounds=(0, None))\n",
    "    return res, A_clique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Program for Shannon entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unconnected_v(graph):\n",
    "    keys = list(graph.keys())\n",
    "    for v in keys:\n",
    "        if len(graph[v]) == 0:\n",
    "            graph.pop(v, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G10 = {1:set({}), 2:set({}), 3:set({}), 4:set({}), 5:set({}), 6:set({})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unconnected_v(G10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets_dict(V, prefix=[], arr_sets={}):\n",
    "    if V == []: return 1\n",
    "    for i in range(len(V)):\n",
    "        subset = prefix + [V[i]]\n",
    "        arr_sets[tuple(subset)] = len(arr_sets)\n",
    "        subsets_dict(V[i+1:], subset, arr_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for subset in subsets_dict:\n",
    "        subset_len = len(subset)\n",
    "        subset_i = subsets_dict[subset]\n",
    "        a_lq = np.zeros(num_sets)\n",
    "        if subset_len > 1:\n",
    "            a_lq[subset_i] = -1 * (subset_len)\n",
    "            a_mq = np.zeros(num_sets)\n",
    "            a_mq[subset_i] = subset_len - 1\n",
    "            s = set(subset)\n",
    "            for v in subset:\n",
    "                sub_i = subsets_dict[tuple(x for x in subset if v != x)]\n",
    "                a_lq[sub_i] = 1    \n",
    "                a_mq[sub_i] = -1\n",
    "            A += [a_lq, a_mq]\n",
    "            b += [0, 0]\n",
    "        else:\n",
    "            a_lq[subset_i] = 1\n",
    "            A += [a_lq]\n",
    "            b += [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_2(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        for j in range(i, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            a_lq = np.zeros(num_sets)\n",
    "            if len(subset_i) < 2 and pos_i == pos_j: \n",
    "                a_lq[pos_i] = 1\n",
    "                A += [a_lq]\n",
    "                b += [1]\n",
    "#                 print(\"identical\", subset_i)\n",
    "            else:\n",
    "                a_mq = np.zeros(num_sets)\n",
    "                subset_i = set(subset_i)\n",
    "                subset_j = set(subset_j)\n",
    "                subset_ij_u = subset_i | subset_j\n",
    "                subset_ij_i = subset_i & subset_j\n",
    "                if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                    if len(subset_i) > len(subset_j):\n",
    "                        a_mq[pos_i] = -1\n",
    "                        a_mq[pos_j] = 1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    elif len(subset_i) < len(subset_j):\n",
    "                        a_mq[pos_i] = 1\n",
    "                        a_mq[pos_j] = -1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "#                     print(\"intersect each other\", subset_i, subset_j)\n",
    "                else:\n",
    "#                     print(\"not intersection of each other\", subset_i, subset_j)\n",
    "                    a_lq[pos_i] = -1\n",
    "                    a_lq[pos_j] = -1\n",
    "                    a_lq[subsets_dict[tuple(subset_ij_u)]] = 1\n",
    "                    if len(subset_ij_i) > 0:\n",
    "                        a_lq[subsets_dict[tuple(subset_ij_i)]] = 1\n",
    "                    A += [a_lq]\n",
    "                    b += [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version is missing a lot of important conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_3(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        for j in range(i, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            a_mq = np.zeros(num_sets)\n",
    "            if len(subset_i) < 2 and pos_i == pos_j: \n",
    "                a_mq[pos_i] = 1\n",
    "                A += [a_mq]\n",
    "                b += [1]\n",
    "            else:\n",
    "                subset_i = set(subset_i)\n",
    "                subset_j = set(subset_j)\n",
    "                subset_ij_u = subset_i | subset_j\n",
    "                subset_ij_i = subset_i & subset_j\n",
    "                if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                    if len(subset_i) > len(subset_j):\n",
    "                        a_mq[pos_i] = -1\n",
    "                        a_mq[pos_j] = 1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    elif len(subset_i) < len(subset_j):\n",
    "                        a_mq[pos_i] = 1\n",
    "                        a_mq[pos_j] = -1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "        \n",
    "        if len(subset_i) > 1:\n",
    "            a_lq = np.zeros(num_sets)\n",
    "            a_lq[pos_i] = 1\n",
    "            for v in subset_i:\n",
    "                sub_i = subsets_dict[(v,)]\n",
    "                a_lq[sub_i] = -1\n",
    "            A += [a_lq]\n",
    "            b += [0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_eq_dict(graph, eq_dict={}):\n",
    "    for v in graph:\n",
    "        n = tuple(graph[v])\n",
    "        n_v = tuple(graph[v] | {v})\n",
    "        if n in eq_dict:\n",
    "            eq_dict[n_v] = eq_dict[n]\n",
    "        else:\n",
    "            eq_dict[n] = n_v    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_4(graph, subsets_dict, eq_dict,  A=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        rep_i = subset_i in eq_dict\n",
    "        for j in range(i + 1, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            rep_j = subset_j in eq_dict            \n",
    "            \n",
    "            val_i, val_j = (), ()\n",
    "            \n",
    "            if rep_i:\n",
    "                pos_i = subsets_dict[eq_dict[subset_i]]\n",
    "            if rep_j:\n",
    "                pos_j = subsets_dict[eq_dict[subset_j]]\n",
    "\n",
    "            subset_i_s = set(subset_i)\n",
    "            subset_j_s = set(subset_j)\n",
    "            subset_ij_u = tuple(subset_i_s | subset_j_s)\n",
    "            subset_ij_i = tuple(subset_i_s & subset_j_s)\n",
    "            \n",
    "            pos_u = subsets_dict[subset_ij_u]\n",
    "            \n",
    "            if subset_ij_u in eq_dict:\n",
    "                pos_u = subsets_dict[eq_dict[subset_ij_u]]\n",
    "            \n",
    "            if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                if pos_i == pos_j: \n",
    "#                     print('skipped mq same pos', subset_i, subset_j, subset_ij_u, subset_ij_i, pos_i, pos_j)\n",
    "                    continue\n",
    "                diff = len(subset_i) - len(subset_j)\n",
    "                a_mq = np.zeros(num_sets) \n",
    "                if diff == 1:\n",
    "                    a_mq[pos_i] = -1\n",
    "                    a_mq[pos_j] = 1\n",
    "                    A += [a_mq]\n",
    "#                     print('mq', subset_i, subset_j, subset_ij_u, subset_ij_i, pos_i, pos_j, a_mq)\n",
    "                elif diff == -1:\n",
    "                    a_mq[pos_i] = 1\n",
    "                    a_mq[pos_j] = -1\n",
    "                    A += [a_mq]\n",
    "#                     print('mq', subset_i, subset_j, subset_ij_u, subset_ij_i, pos_i, pos_j, a_mq)\n",
    "            else:\n",
    "                if ((pos_i == pos_u and pos_j != pos_u) or \n",
    "                (pos_j == pos_u and pos_i != pos_u)): \n",
    "#                     print('skipped lq', subset_i, subset_j, subset_ij_u, subset_ij_i, pos_i, pos_j)\n",
    "                    continue\n",
    "                a_lq = np.zeros(num_sets) \n",
    "                \n",
    "                a_lq[pos_i] = -1\n",
    "                a_lq[pos_j] = -1\n",
    "                a_lq[pos_u] = 1\n",
    "                \n",
    "                if len(subset_ij_i) > 0:\n",
    "                    if subset_ij_i in eq_dict:\n",
    "                        pos_ij = subsets_dict[eq_dict[subset_ij_i]]\n",
    "                        if pos_i != pos_j:\n",
    "                            if pos_i == pos_ij:\n",
    "                                a_lq[pos_i] = 0\n",
    "                            elif pos_j == pos_ij:\n",
    "                                a_lq[pos_j] = 0\n",
    "                            else:\n",
    "                                a_lq[pos_ij] = 1\n",
    "                    else:\n",
    "                        pos_ij = subsets_dict[subset_ij_i]\n",
    "                        a_lq[pos_ij] = 1\n",
    "                A += [a_lq]\n",
    "#                 print('lq', subset_i, subset_j, subset_ij_u, subset_ij_i, pos_i, pos_j, a_lq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_eq_set(graph, subsets_dict, A=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for v in graph:\n",
    "        n = tuple(graph[v])\n",
    "        n_v = tuple(graph[v] | {v})\n",
    "        a_eq = np.zeros(num_sets)\n",
    "        a_eq[subsets_dict[n_v]] = 1\n",
    "        if len(n) > 0: \n",
    "            a_eq[subsets_dict[n]] = -1\n",
    "        A += [a_eq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_eq_set_2(subsets_dict, eq_dict, A=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for k in eq_dict:\n",
    "        v = eq_dict[k]\n",
    "        a_eq = np.zeros(num_sets)\n",
    "        a_eq[subsets_dict[k]] = 1\n",
    "        a_eq[subsets_dict[v]] = -1\n",
    "        A += [a_eq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_A(A=np.array([])):\n",
    "    temp_a = np.ascontiguousarray(A)\n",
    "    unique_a = np.unique(temp_a.view([('', temp_a.dtype)]*temp_a.shape[1]))\n",
    "    A = unique_a.view(temp_a.dtype).reshape((unique_a.shape[0], temp_a.shape[1]))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_v_Ab(V, subsets_dict, A=np.array([]), b=np.array([])):\n",
    "    A = list(A)\n",
    "    b = b.tolist()\n",
    "    print(len(A))\n",
    "    num_sets = len(subsets_dict)\n",
    "    for _v in V:\n",
    "        pos_v = subsets_dict[(_v,)]\n",
    "        temp_a = np.zeros(num_sets)\n",
    "        temp_a[pos_v] = 1\n",
    "        A += [temp_a]\n",
    "        b += [1]\n",
    "    return np.array(A), np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_entropy_1(graph):\n",
    "    # remove all isolated vertices from the graph\n",
    "    remove_unconnected_v(graph)\n",
    "        \n",
    "    V = list(graph.keys())\n",
    "    v_num = len(V)\n",
    "    \n",
    "    if v_num == 0: return 0\n",
    "    \n",
    "    arr_sets = {}\n",
    "    subsets_dict(V, arr_sets=arr_sets)\n",
    "    \n",
    "    eq_dict = {}\n",
    "    entropy_eq_dict(graph, eq_dict=eq_dict)\n",
    "    \n",
    "    A_entropy = []\n",
    "    b_entropy = []\n",
    "    A_entropy_set_2(graph, arr_sets, A=A_entropy, b=b_entropy)\n",
    "    A_entropy = np.array(A_entropy)\n",
    "    b_entropy = np.array(b_entropy, dtype=float)\n",
    "    \n",
    "    A_entropy_eq = []\n",
    "    A_entropy_eq_set(graph, arr_sets, A=A_entropy_eq)\n",
    "    A_entropy_eq = np.array(A_entropy_eq)\n",
    "    b_entropy_eq = np.zeros(A_entropy_eq.shape[0])\n",
    "    \n",
    "    c_clique = np.zeros(len(arr_sets))\n",
    "    c_clique[arr_sets[tuple(V)]] = -1\n",
    "    \n",
    "    print(A_entropy, A_entropy.shape)\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_entropy, b_ub=b_entropy, A_eq=A_entropy_eq, b_eq=b_entropy_eq, bounds=(0, None))\n",
    "    \n",
    "    x = res.x\n",
    "    keys = list(arr_sets.keys())\n",
    "    for i in range(x.shape[0]):\n",
    "        print(keys[i], x[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_entropy(graph):\n",
    "    # remove all isolated vertices from the graph\n",
    "    remove_unconnected_v(graph)\n",
    "        \n",
    "    V = list(graph.keys())\n",
    "    v_num = len(V)\n",
    "    \n",
    "    if v_num == 0: return 0\n",
    "    \n",
    "    arr_sets = {}\n",
    "    subsets_dict(V, arr_sets=arr_sets)\n",
    "    \n",
    "    eq_dict = {}\n",
    "    entropy_eq_dict(graph, eq_dict=eq_dict)\n",
    "    \n",
    "    print(eq_dict)\n",
    "    \n",
    "    A_entropy = []\n",
    "    A_entropy_set_4(graph, arr_sets, eq_dict, A=A_entropy)\n",
    "    A_entropy = np.array(A_entropy)\n",
    "    print(A_entropy, A_entropy.shape)\n",
    "    \n",
    "    A_entropy = remove_duplicate_A(A=A_entropy)\n",
    "    b_entropy = np.zeros(A_entropy.shape[0])\n",
    "    \n",
    "    print(A_entropy, A_entropy.shape)\n",
    "    A_entropy, b_entropy = add_v_Ab(V, arr_sets, A=A_entropy, b=b_entropy)\n",
    "    \n",
    "    A_entropy_eq = []\n",
    "    A_entropy_eq_set_2(arr_sets, eq_dict, A=A_entropy_eq)\n",
    "    A_entropy_eq = np.array(A_entropy_eq)\n",
    "    b_entropy_eq = np.zeros(A_entropy_eq.shape[0])\n",
    "    \n",
    "    c_clique = np.zeros(len(arr_sets))\n",
    "    c_clique[arr_sets[tuple(V)]] = -1\n",
    "    \n",
    "    print(A_entropy, A_entropy.shape)\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_entropy, b_ub=b_entropy, A_eq=A_entropy_eq, b_eq=b_entropy_eq, bounds=(0, None))\n",
    "    \n",
    "    x = res.x\n",
    "    keys = list(arr_sets.keys())\n",
    "    for i in range(x.shape[0]):\n",
    "        print(keys[i], x[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = {1:{2,5,6}, 2:{1,3,6}, 3:{2,4}, 4:{3,5,7}, 5:{1,4}, 6:{1,2,7}, 7:{4,6}}\n",
    "G2 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4,6}, 4:{3,5}, 5:{1,4}, 6:{1,3,7}, 7:{2,6}}\n",
    "G3 = {1:{2,5,6}, 2:{1,3}, 3:{2,4,6}, 4:{3,5,7}, 5:{1,4}, 6:{1,3,7}, 7:{4,6}}\n",
    "G4 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4,6}, 4:{3,5,7}, 5:{1,4}, 6:{1,3,7}, 7:{2,4,6}}\n",
    "G5 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4}, 4:{3,5}, 5:{1,4}, 6:{1,7}, 7:{2,6}}\n",
    "G6 = {1:{2,5,6}, 2:{1,3}, 3:{2,4,7}, 4:{3,5}, 5:{1,4}, 6:{1,7}, 7:{3,6}}\n",
    "G7 = {1:{2,3,4,5,6,7}, 2:{1,3,4,5,6,7}, 3:{1,2,4,5,6,7}, 4:{1,2,3,5,6,7}, 5:{1,2,3,4,6,7}, 6:{1,2,3,4,5,7}, 7:{1,2,3,4,5,6}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "G8 = {1:{2,5}, 2:{1,3}, 3:{2,4}, 4:{3,5}, 5:{1,4}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "G9 = {1:{2,6}, 2:{1,3}, 3:{2,4}, 4:{3,5}, 5:{4,6}, 6:{1,5}}\n",
    "G10 = {1:{2}, 2:{1}, 3:set({}), 4:set({}), 5:set({}), 6:set({})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "G11 = {1:{3,4}, 2:{3,4}, 3:{1,2}, 4: {1,2}}\n",
    "draw_graph(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 5, 6): (1, 2, 5, 6), (1, 3, 6): (1, 2, 3, 6), (2, 4): (2, 3, 4), (3, 5, 7): (3, 4, 5, 7), (1, 4): (1, 4, 5), (1, 2, 7): (1, 2, 6, 7), (4, 6): (4, 6, 7)}\n",
      "[[ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  1. -1.  0.]\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]] (6466, 127)\n",
      "[[-1.  0.  0. ...  0.  0. -1.]\n",
      " [-1.  0.  0. ...  0. -1.  0.]\n",
      " [-1.  0.  0. ... -1.  0.  0.]\n",
      " ...\n",
      " [ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1.  0.  0. ...  0.  0.  0.]] (6466, 127)\n",
      "6466\n",
      "[[-1.  0.  0. ...  0.  0. -1.]\n",
      " [-1.  0.  0. ...  0. -1.  0.]\n",
      " [-1.  0.  0. ... -1.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  1.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (6473, 127)\n"
     ]
    }
   ],
   "source": [
    "lp_entropy(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G11 = {1:{2,3,4,5}, 2:{1,3}, 3:{1,2}, 4: {1,5}, 5:{1,4}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_entropy(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.optimize.show_options('linprog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1., 2., 2., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 2., 2., 2., 1.,\n",
    "       2., 3., 3., 3., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_approx_identical_entropy(G1, G2):\n",
    "    entropy_g1 = lp_entropy(G1)\n",
    "    entropy_g2 = lp_entropy(G2)\n",
    "    print(np.round(entropy_g1.x))\n",
    "    print(np.round(entropy_g2.x))\n",
    "    return np.array_equal(np.round(entropy_g1.x), np.round(entropy_g2.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = {1:{2,3,4,5}, 2:{1,3}, 3:{1,2}, 4: {1,5}, 5:{1,4}}\n",
    "draw_graph(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = {1:{2,3,4,5}, 2:{1,3,4}, 3:{1,2}, 4: {1,2,5}, 5:{1,4}}\n",
    "draw_graph(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "G3 = {1:{2,3,4,5}, 2:{1,3,4}, 3:{1,2,4}, 4: {1,2,3,5}, 5:{1,4}}\n",
    "draw_graph(G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "G4 = {1:{2,3,4,5}, 2:{1,3,4}, 3:{1,2,5}, 4: {1,2,5}, 5:{1,3,4}}\n",
    "draw_graph(G4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "G5 = {1:{2,4,5}, 2:{1,3,4}, 3:{2,5}, 4: {1,2,5}, 5:{1,3,4}}\n",
    "draw_graph(G5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G6 = {1:{2,3,5}, 2:{1,3,4}, 3:{1,2,5}, 4: {2,5}, 5:{1,3,4}}\n",
    "draw_graph(G6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_approx_identical_entropy(G5,G4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
