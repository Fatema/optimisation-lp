{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Program for fractional clique number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to return all possible subsests for list of vertices V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets(V, prefix=[], arr_sets=[]):\n",
    "    if V == []: return\n",
    "    for i in range(len(V)):\n",
    "        subset = prefix + [V[i]]\n",
    "        arr_sets += [subset]\n",
    "        subsets(V[i+1:], subset, arr_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clique(graph, v_set):\n",
    "    if len(v_set) < 2: return True\n",
    "    for i in range(len(v_set)):\n",
    "        i_set = set(v_set[:i] + v_set[i+1:])\n",
    "        g_set = graph[v_set[i]]\n",
    "        if i_set & g_set != i_set :\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_clique_set(graph, v_encode, subsets, A=[]):\n",
    "    for subset in subsets:\n",
    "        if check_clique(graph, subset):\n",
    "            A += [sum([v_encode[v] for v in subset])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_clique(graph):\n",
    "    V = list(graph.keys())\n",
    "    v_encode = {}\n",
    "    v_num = len(V)\n",
    "    \n",
    "    for i in range(v_num):\n",
    "        temp = np.zeros(v_num)\n",
    "        temp[i] = -1\n",
    "        v_encode[V[i]] = temp\n",
    "    \n",
    "    arr_sets = []\n",
    "    subsets(V, arr_sets=arr_sets)\n",
    "    \n",
    "    b_clique = np.negative(np.ones(v_num))\n",
    "    A_clique = []\n",
    "    A_clique_set(graph, v_encode, arr_sets,A=A_clique)\n",
    "    A_clique = np.transpose(np.array(A_clique))\n",
    "    c_clique = np.ones(A_clique.shape[1])\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_clique, b_ub=b_clique, bounds=(0, None))\n",
    "    return res, A_clique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Program for Shannon entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removed_unconnected_v(graph):\n",
    "    keys = list(graph.keys())\n",
    "    for v in keys:\n",
    "        if len(graph[v]) == 0:\n",
    "            graph.pop(v, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "G10 = {1:set({}), 2:set({}), 3:set({}), 4:set({}), 5:set({}), 6:set({})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_unconnected_v(G10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets_dict(V, prefix=[], arr_sets={}):\n",
    "    if V == []: return 1\n",
    "    for i in range(len(V)):\n",
    "        subset = prefix + [V[i]]\n",
    "        arr_sets[tuple(subset)] = len(arr_sets)\n",
    "        subsets_dict(V[i+1:], subset, arr_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for subset in subsets_dict:\n",
    "        subset_len = len(subset)\n",
    "        subset_i = subsets_dict[subset]\n",
    "        a_lq = np.zeros(num_sets)\n",
    "        if subset_len > 1:\n",
    "            a_lq[subset_i] = -1 * (subset_len)\n",
    "            a_mq = np.zeros(num_sets)\n",
    "            a_mq[subset_i] = subset_len - 1\n",
    "            s = set(subset)\n",
    "            for v in subset:\n",
    "                sub_i = subsets_dict[tuple(x for x in subset if v != x)]\n",
    "                a_lq[sub_i] = 1    \n",
    "                a_mq[sub_i] = -1\n",
    "            A += [a_lq, a_mq]\n",
    "            b += [0, 0]\n",
    "        else:\n",
    "            a_lq[subset_i] = 1\n",
    "            A += [a_lq]\n",
    "            b += [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_2(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        for j in range(i, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            a_lq = np.zeros(num_sets)\n",
    "            if len(subset_i) < 2 and pos_i == pos_j: \n",
    "                a_lq[pos_i] = 1\n",
    "                A += [a_lq]\n",
    "                b += [1]\n",
    "#                 print(\"identical\", subset_i)\n",
    "            else:\n",
    "                a_mq = np.zeros(num_sets)\n",
    "                subset_i = set(subset_i)\n",
    "                subset_j = set(subset_j)\n",
    "                subset_ij_u = subset_i | subset_j\n",
    "                subset_ij_i = subset_i & subset_j\n",
    "                if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                    if len(subset_i) > len(subset_j):\n",
    "                        a_mq[pos_i] = -1\n",
    "                        a_mq[pos_j] = 1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    elif len(subset_i) < len(subset_j):\n",
    "                        a_mq[pos_i] = 1\n",
    "                        a_mq[pos_j] = -1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "#                     print(\"intersect each other\", subset_i, subset_j)\n",
    "                else:\n",
    "#                     print(\"not intersection of each other\", subset_i, subset_j)\n",
    "                    a_lq[pos_i] = -1\n",
    "                    a_lq[pos_j] = -1\n",
    "                    a_lq[subsets_dict[tuple(subset_ij_u)]] = 1\n",
    "                    if len(subset_ij_i) > 0:\n",
    "                        a_lq[subsets_dict[tuple(subset_ij_i)]] = 1\n",
    "                    A += [a_lq]\n",
    "                    b += [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version is missing a lot of important conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_set_3(V, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        for j in range(i, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            a_mq = np.zeros(num_sets)\n",
    "            if len(subset_i) < 2 and pos_i == pos_j: \n",
    "                a_mq[pos_i] = 1\n",
    "                A += [a_mq]\n",
    "                b += [1]\n",
    "            else:\n",
    "                subset_i = set(subset_i)\n",
    "                subset_j = set(subset_j)\n",
    "                subset_ij_u = subset_i | subset_j\n",
    "                subset_ij_i = subset_i & subset_j\n",
    "                if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                    if len(subset_i) > len(subset_j):\n",
    "                        a_mq[pos_i] = -1\n",
    "                        a_mq[pos_j] = 1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    elif len(subset_i) < len(subset_j):\n",
    "                        a_mq[pos_i] = 1\n",
    "                        a_mq[pos_j] = -1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "        \n",
    "        if len(subset_i) > 1:\n",
    "            a_lq = np.zeros(num_sets)\n",
    "            a_lq[pos_i] = 1\n",
    "            for v in subset_i:\n",
    "                sub_i = subsets_dict[(v,)]\n",
    "                a_lq[sub_i] = -1\n",
    "            A += [a_lq]\n",
    "            b += [0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_eq_dict(graph, eq_dicts = {}, subsets):\n",
    "    subsets.sort(key=len)\n",
    "    for v in graph:\n",
    "        n = tuple(graph[v])\n",
    "        n_v = tuple(graph[v] | {v})\n",
    "        eq_dicts[n] += [n_v]\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-42fe81a0d207>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-42fe81a0d207>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    rep_i =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def A_entropy_set_4(graph, subsets_dict, A=[], b=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    subsets = list(subsets_dict.keys())\n",
    "    eq_dict = {}\n",
    "    entropy_eq_dict(graph, eq_dict)\n",
    "    for i in range(num_sets):\n",
    "        subset_i = subsets[i]\n",
    "        pos_i = subsets_dict[subset_i]\n",
    "        for j in range(i, num_sets):\n",
    "            subset_j = subsets[j]\n",
    "            pos_j = subsets_dict[subset_j]\n",
    "            a_mq = np.zeros(num_sets)\n",
    "            if len(subset_i) < 2 and pos_i == pos_j: \n",
    "                a_mq[pos_i] = 1\n",
    "                A += [a_mq]\n",
    "                b += [1]\n",
    "            else:\n",
    "                rep_i = ()\n",
    "                if subset_i in eq_dict: \n",
    "                    rep_i = \n",
    "                    \n",
    "                subset_i = set(subset_i)\n",
    "                subset_j = set(subset_j)\n",
    "                subset_ij_u = subset_i | subset_j\n",
    "                subset_ij_i = subset_i & subset_j\n",
    "                \n",
    "                if (subset_ij_i == subset_i or subset_ij_i == subset_j):\n",
    "                    diff = len(subset_i) - len(subset_j)\n",
    "                    if diff == 1:\n",
    "                        a_mq[pos_i] = -1\n",
    "                        a_mq[pos_j] = 1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    elif diff == -1:\n",
    "                        a_mq[pos_i] = 1\n",
    "                        a_mq[pos_j] = -1\n",
    "                        A += [a_mq]\n",
    "                        b += [0]\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_entropy_eq_set(graph, subsets_dict, A=[]):\n",
    "    num_sets = len(subsets_dict)\n",
    "    for v in graph:\n",
    "        n = tuple(graph[v])\n",
    "        n_v = tuple(graph[v] | {v})\n",
    "        a_eq = np.zeros(num_sets)\n",
    "        a_eq[subsets_dict[n_v]] = 1\n",
    "        if len(n) > 0: \n",
    "            a_eq[subsets_dict[n]] = -1\n",
    "        A += [a_eq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_entropy(graph):\n",
    "    # remove all isolated vertices from the graph\n",
    "    removed_unconnected_v(graph)\n",
    "        \n",
    "    V = list(graph.keys())\n",
    "    v_encode = {}\n",
    "    v_num = len(V)\n",
    "    \n",
    "    if v_num == 0: return 0\n",
    "    \n",
    "    for i in range(v_num):\n",
    "        temp = np.zeros(v_num)\n",
    "        temp[i] = -1\n",
    "        v_encode[V[i]] = temp\n",
    "    \n",
    "    arr_sets = {}\n",
    "    subsets_dict(V, arr_sets=arr_sets)\n",
    "    \n",
    "    A_entropy = []\n",
    "    b_entropy = []\n",
    "    A_entropy_set_2(V, arr_sets, A=A_entropy, b=b_entropy)\n",
    "    A_entropy = np.array(A_entropy)\n",
    "    b_entropy = np.array(b_entropy, dtype=float)\n",
    "    \n",
    "    A_entropy_eq = []\n",
    "    A_entropy_eq_set(graph, arr_sets, A=A_entropy_eq)\n",
    "    A_entropy_eq = np.array(A_entropy_eq)\n",
    "    b_entropy_eq = np.zeros(A_entropy_eq.shape[0])\n",
    "    \n",
    "    c_clique = np.zeros(len(arr_sets))\n",
    "    c_clique[arr_sets[tuple(V)]] = -1\n",
    "    \n",
    "    print(A_entropy, A_entropy.shape)\n",
    "    \n",
    "    res = linprog(c_clique, A_ub=A_entropy, b_ub=b_entropy, A_eq=A_entropy_eq, b_eq=b_entropy_eq, bounds=(0, None))\n",
    "    \n",
    "    x = res.x\n",
    "    keys = list(arr_sets.keys())\n",
    "    for i in range(x.shape[0]):\n",
    "        print(keys[i], x[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = {1:{2,5,6}, 2:{1,3,6}, 3:{2,4}, 4:{3,5,7}, 5:{1,4}, 6:{1,2,7}, 7:{4,6}}\n",
    "G2 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4,6}, 4:{3,5}, 5:{1,4}, 6:{1,3,7}, 7:{2,6}}\n",
    "G3 = {1:{2,5,6}, 2:{1,3}, 3:{2,4,6}, 4:{3,5,7}, 5:{1,4}, 6:{1,3,7}, 7:{4,6}}\n",
    "G4 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4,6}, 4:{3,5,7}, 5:{1,4}, 6:{1,3,7}, 7:{2,4,6}}\n",
    "G5 = {1:{2,5,6}, 2:{1,3,7}, 3:{2,4}, 4:{3,5}, 5:{1,4}, 6:{1,7}, 7:{2,6}}\n",
    "G6 = {1:{2,5,6}, 2:{1,3}, 3:{2,4,7}, 4:{3,5}, 5:{1,4}, 6:{1,7}, 7:{3,6}}\n",
    "G7 = {1:{2,3,4,5,6,7}, 2:{1,3,4,5,6,7}, 3:{1,2,4,5,6,7}, 4:{1,2,3,5,6,7}, 5:{1,2,3,4,6,7}, 6:{1,2,3,4,5,7}, 7:{1,2,3,4,5,6}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "G8 = {1:{2,5}, 2:{1,3}, 3:{2,4}, 4:{3,5}, 5:{1,4}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "G9 = {1:{2,6}, 2:{1,3}, 3:{2,4}, 4:{3,5}, 5:{4,6}, 6:{1,5}}\n",
    "G10 = {1:{2}, 2:{1}, 3:set({}), 4:set({}), 5:set({}), 6:set({})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "G11 = {1:{3,4,5}, 2:{3,4}, 3:{1,2}, 4: {1,2}, 5:{1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (470, 31)\n",
      "(1,) 1.0\n",
      "(1, 2) 1.9999999999999973\n",
      "(1, 2, 3) 1.9999999999999964\n",
      "(1, 2, 3, 4) 1.9999999999999978\n",
      "(1, 2, 3, 4, 5) 1.9999999999999973\n",
      "(1, 2, 3, 5) 1.9999999999999964\n",
      "(1, 2, 4) 1.9999999999999978\n",
      "(1, 2, 4, 5) 1.9999999999999996\n",
      "(1, 2, 5) 1.9999999999999982\n",
      "(1, 3) 0.9999999999999992\n",
      "(1, 3, 4) 1.9999999999999991\n",
      "(1, 3, 4, 5) 2.0000000000000004\n",
      "(1, 3, 5) 1.0000000000000042\n",
      "(1, 4) 1.9999999999999971\n",
      "(1, 4, 5) 1.9999999999999991\n",
      "(1, 5) 1.0000000000000007\n",
      "(2,) 1.0\n",
      "(2, 3) 1.0000000000000027\n",
      "(2, 3, 4) 1.0000000000000027\n",
      "(2, 3, 4, 5) 1.999999999999997\n",
      "(2, 3, 5) 1.9999999999999956\n",
      "(2, 4) 1.0000000000000022\n",
      "(2, 4, 5) 1.9999999999999978\n",
      "(2, 5) 1.9999999999999938\n",
      "(3,) 2.4424906541752387e-15\n",
      "(3, 4) 1.0000000000000036\n",
      "(3, 4, 5) 2.0000000000000004\n",
      "(3, 5) 0.9999999999999998\n",
      "(4,) 0.9999999999999979\n",
      "(4, 5) 1.9999999999999956\n",
      "(5,) 0.9999999999999971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     con: array([ 0.00000000e+00,  8.88178420e-16,  8.88178420e-16, -4.44089210e-16,\n",
       "       -6.66133815e-16])\n",
       "     fun: -1.9999999999999973\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 750\n",
       "   slack: array([ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00, -7.77156117e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        4.21884749e-15,  1.00000000e+00,  1.00000000e+00,  6.66133815e-16,\n",
       "        2.66453526e-15,  6.21724894e-15,  4.88498131e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  4.44089210e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        3.21964677e-15,  4.44089210e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        6.66133815e-16,  1.00000000e+00,  1.00000000e+00, -8.88178420e-16,\n",
       "        4.44089210e-16,  0.00000000e+00, -8.88178420e-16,  4.44089210e-16,\n",
       "        2.22044605e-15,  8.88178420e-16,  0.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  5.10702591e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "       -2.22044605e-16,  1.00000000e+00,  3.55271368e-15,  2.22044605e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.77635684e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  3.33066907e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.33226763e-15,  8.88178420e-16,  0.00000000e+00, -8.88178420e-16,\n",
       "        1.33226763e-15,  8.88178420e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  5.10702591e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        8.88178420e-16,  1.00000000e+00,  1.00000000e+00, -1.33226763e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  8.88178420e-16,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "       -4.44089210e-16,  4.44089210e-16,  0.00000000e+00,  2.22044605e-15,\n",
       "        1.33226763e-15,  1.00000000e+00, -1.33226763e-15,  1.77635684e-15,\n",
       "        5.32907052e-15,  6.66133815e-16,  2.22044605e-15,  8.88178420e-16,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  8.88178420e-16,\n",
       "       -4.44089210e-16, -2.22044605e-15, -8.88178420e-16,  1.00000000e+00,\n",
       "       -1.77635684e-15, -3.10862447e-15,  1.00000000e+00,  2.22044605e-16,\n",
       "       -1.77635684e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  4.44089210e-16,  1.77635684e-15,  1.00000000e+00,\n",
       "       -4.44089210e-16,  3.55271368e-15,  2.00000000e+00,  1.00000000e+00,\n",
       "       -3.10862447e-15,  1.00000000e+00,  1.00000000e+00,  1.77635684e-15,\n",
       "        1.00000000e+00, -4.44089210e-16,  4.44089210e-16, -1.77635684e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00, -8.88178420e-16,  4.44089210e-16,  8.88178420e-16,\n",
       "        1.33226763e-15,  3.10862447e-15,  2.66453526e-15,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.77635684e-15, -8.88178420e-16,\n",
       "       -7.77156117e-16,  1.99840144e-15,  3.55271368e-15,  4.66293670e-15,\n",
       "        6.66133815e-16,  2.22044605e-16, -1.11022302e-15,  1.00000000e+00,\n",
       "        2.66453526e-15,  4.44089210e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.44249065e-15,\n",
       "        5.66213743e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.33226763e-15,  1.33226763e-15,\n",
       "        3.99680289e-15,  3.55271368e-15,  5.77315973e-15,  2.44249065e-15,\n",
       "        4.44089210e-16,  1.00000000e+00,  1.00000000e+00,  4.88498131e-15,\n",
       "        2.66453526e-15,  1.33226763e-15,  3.99680289e-15,  1.00000000e+00,\n",
       "        1.77635684e-15,  5.77315973e-15,  4.66293670e-15,  7.99360578e-15,\n",
       "        7.10542736e-15,  4.44089210e-15,  1.00000000e+00,  3.99680289e-15,\n",
       "        1.00000000e+00,  9.99200722e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        5.55111512e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  4.44089210e-15,  3.55271368e-15,  3.99680289e-15,\n",
       "        3.55271368e-15,  8.88178420e-16,  2.66453526e-15,  4.44089210e-15,\n",
       "        3.99680289e-15,  1.00000000e+00,  1.00000000e+00,  4.44089210e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  4.99600361e-15, -2.66453526e-15, -2.10942375e-15,\n",
       "       -4.66293670e-15,  2.66453526e-15,  2.88657986e-15,  1.66533454e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  3.55271368e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.33226763e-15,  1.00000000e+00,\n",
       "        1.00000000e+00, -1.99840144e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.33226763e-15,  3.66373598e-15,  1.99840144e-15,  6.66133815e-16,\n",
       "       -6.66133815e-16,  1.00000000e+00,  1.00000000e+00,  4.44089210e-16,\n",
       "        1.00000000e+00,  2.00000000e+00,  5.66213743e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  3.33066907e-15,  1.33226763e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.22044605e-15, -4.44089210e-16,\n",
       "        1.00000000e+00,  7.54951657e-15,  5.32907052e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  4.88498131e-15,  1.00000000e+00,  8.88178420e-16,\n",
       "        2.44249065e-15,  3.55271368e-15,  7.99360578e-15,  7.99360578e-15,\n",
       "        7.10542736e-15,  3.99680289e-15,  3.77475828e-15,  9.10382880e-15,\n",
       "        7.54951657e-15,  4.44089210e-15,  1.00000000e+00,  4.88498131e-15,\n",
       "        4.66293670e-15,  4.44089210e-15,  1.77635684e-15,  2.66453526e-15,\n",
       "        7.10542736e-15,  1.99840144e-15, -1.33226763e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  4.10782519e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        3.55271368e-15,  1.00000000e+00,  2.00000000e+00,  4.44089210e-16,\n",
       "        3.99680289e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  6.66133815e-15,  3.10862447e-15,  1.00000000e+00,\n",
       "        3.88578059e-15,  1.77635684e-15,  1.00000000e+00,  1.11022302e-15,\n",
       "        4.32986980e-15,  3.55271368e-15,  1.33226763e-15,  1.00000000e+00,\n",
       "        3.55271368e-15,  1.00000000e+00,  2.44249065e-15,  6.88338275e-15,\n",
       "        6.21724894e-15,  2.66453526e-15,  2.66453526e-15,  3.33066907e-15,\n",
       "        1.77635684e-15, -6.66133815e-16, -1.11022302e-15,  3.77475828e-15,\n",
       "        3.55271368e-15, -8.88178420e-16, -5.55111512e-16, -2.22044605e-16,\n",
       "        3.55271368e-15,  0.00000000e+00,  2.66453526e-15,  2.66453526e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.22044605e-15,  1.00000000e+00,\n",
       "        1.00000000e+00, -2.22044605e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        4.21884749e-15,  1.00000000e+00,  1.00000000e+00,  3.33066907e-15,\n",
       "        0.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.22044605e-15,\n",
       "        3.55271368e-15,  8.88178420e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  4.44089210e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        4.21884749e-15,  1.00000000e+00, -1.33226763e-15,  4.44089210e-16,\n",
       "        1.33226763e-15, -4.44089210e-16,  1.00000000e+00, -8.88178420e-16,\n",
       "        2.66453526e-15,  3.10862447e-15,  4.77395901e-15,  3.44169138e-15,\n",
       "        2.88657986e-15,  1.33226763e-15,  1.00000000e+00, -8.88178420e-16,\n",
       "        3.10862447e-15,  2.00000000e+00,  1.00000000e+00, -3.55271368e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.33226763e-15,  1.00000000e+00,\n",
       "        8.88178420e-16,  2.66453526e-15,  1.77635684e-15,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00, -1.77635684e-15,\n",
       "        1.99840144e-15,  5.32907052e-15,  7.88258347e-15,  5.10702591e-15,\n",
       "        4.32986980e-15,  2.22044605e-15,  1.55431223e-15,  3.99680289e-15,\n",
       "        3.33066907e-15,  6.55031585e-15,  5.77315973e-15,  3.55271368e-15,\n",
       "        1.00000000e+00,  2.22044605e-15,  1.00000000e+00,  6.66133815e-16,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.11022302e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00, -3.33066907e-15, -2.44249065e-15,\n",
       "       -2.22044605e-16,  1.00000000e+00,  4.44089210e-16,  5.66213743e-15,\n",
       "        8.88178420e-16,  2.22044605e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        4.88498131e-15,  1.00000000e+00, -2.77555756e-15, -1.99840144e-15,\n",
       "        2.66453526e-15,  2.10942375e-15,  1.00000000e+00, -5.55111512e-16,\n",
       "        1.00000000e+00,  2.88657986e-15])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
       "       2.00000000e+00, 2.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
       "       2.00000000e+00, 1.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
       "       1.00000000e+00, 2.00000000e+00, 2.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 2.00000000e+00,\n",
       "       2.00000000e+00, 1.00000000e+00, 2.00000000e+00, 2.00000000e+00,\n",
       "       2.44249065e-15, 1.00000000e+00, 2.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 2.00000000e+00, 1.00000000e+00])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_entropy(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "G11 = {1:{2,3,4,5}, 2:{1,3}, 3:{1,2}, 4: {1,5}, 5:{1,4}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (470, 31)\n",
      "(1,) 0.9999999999999998\n",
      "(1, 2) 1.9999999999999891\n",
      "(1, 2, 3) 1.9999999999999978\n",
      "(1, 2, 3, 4) 2.999999999999993\n",
      "(1, 2, 3, 4, 5) 2.9999999999999933\n",
      "(1, 2, 3, 5) 2.999999999999994\n",
      "(1, 2, 4) 2.999999999999994\n",
      "(1, 2, 4, 5) 2.9999999999999827\n",
      "(1, 2, 5) 2.999999999999996\n",
      "(1, 3) 1.9999999999999882\n",
      "(1, 3, 4) 2.9999999999999907\n",
      "(1, 3, 4, 5) 2.99999999999999\n",
      "(1, 3, 5) 2.9999999999999822\n",
      "(1, 4) 1.9999999999999953\n",
      "(1, 4, 5) 1.999999999999999\n",
      "(1, 5) 1.9999999999999873\n",
      "(2,) 1.0\n",
      "(2, 3) 1.999999999999994\n",
      "(2, 3, 4) 2.9999999999999893\n",
      "(2, 3, 4, 5) 2.9999999999999933\n",
      "(2, 3, 5) 2.9999999999999876\n",
      "(2, 4) 2.0000000000000004\n",
      "(2, 4, 5) 2.0000000000000067\n",
      "(2, 5) 2.000000000000002\n",
      "(3,) 0.9999999999999999\n",
      "(3, 4) 1.9999999999999971\n",
      "(3, 4, 5) 2.000000000000001\n",
      "(3, 5) 1.9999999999999962\n",
      "(4,) 0.9999999999999998\n",
      "(4, 5) 1.0000000000000038\n",
      "(5,) 0.9999999999999984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     con: array([ 0.00000000e+00, -2.22044605e-15, -8.65973959e-15,  1.33226763e-14,\n",
       "       -3.55271368e-15])\n",
       "     fun: -2.9999999999999933\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 830\n",
       "   slack: array([ 2.22044605e-16,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.06581410e-14,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  6.21724894e-15,  2.37587727e-14,  5.99520433e-15,\n",
       "        1.13242749e-14,  6.21724894e-15,  1.08801856e-14,  1.37667655e-14,\n",
       "        4.21884749e-15,  4.66293670e-15,  1.08801856e-14,  8.65973959e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -8.88178420e-15,  5.55111512e-15,\n",
       "       -1.88737914e-14,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -4.44089210e-15,  1.31006317e-14,\n",
       "       -4.88498131e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00, -4.88498131e-15,  1.02140518e-14, -8.43769499e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  9.10382880e-15,\n",
       "       -1.77635684e-15,  1.06581410e-14,  9.54791801e-15,  7.32747196e-15,\n",
       "        6.21724894e-15, -2.22044605e-15,  4.44089210e-16,  3.55271368e-15,\n",
       "       -8.88178420e-15,  1.00000000e+00,  3.77475828e-15,  6.66133815e-16,\n",
       "        3.55271368e-15, -2.22044605e-15,  5.32907052e-15,  1.11022302e-14,\n",
       "        6.21724894e-15,  1.00000000e+00,  2.10942375e-15,  5.32907052e-15,\n",
       "        0.00000000e+00,  4.66293670e-15,  8.21565038e-15,  2.66453526e-15,\n",
       "        4.44089210e-16,  1.00000000e+00, -8.88178420e-16, -1.19904087e-14,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.22044605e-15, -1.77635684e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  3.55271368e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  3.55271368e-15,  3.10862447e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  6.21724894e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  3.55271368e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  3.55271368e-15,  1.00000000e+00, -4.44089210e-16,\n",
       "       -4.44089210e-16,  1.06581410e-14, -2.66453526e-15,  1.00000000e+00,\n",
       "        2.66453526e-15,  3.55271368e-15,  1.11022302e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        3.99680289e-15,  0.00000000e+00,  5.77315973e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00, -1.28785871e-14, -2.22044605e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  8.43769499e-15,  1.15463195e-14,\n",
       "        1.00000000e+00,  1.19904087e-14,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  6.66133815e-15,  6.21724894e-15,\n",
       "        1.00000000e+00,  4.88498131e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  5.10702591e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        5.55111512e-15,  2.00000000e+00, -1.11022302e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.48769885e-14,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.68753900e-14,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        1.50990331e-14,  1.00000000e+00, -1.33226763e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.53130850e-14,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.77635684e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.86517468e-14,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -6.66133815e-15, -2.44249065e-15,\n",
       "       -6.66133815e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -5.32907052e-15, -5.55111512e-16,\n",
       "        2.22044605e-15, -2.66453526e-15,  2.22044605e-15,  4.44089210e-15,\n",
       "       -8.88178420e-16,  1.00000000e+00,  1.00000000e+00,  4.21884749e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  1.00000000e+00,  4.21884749e-15,\n",
       "        1.00000000e+00,  2.00000000e+00,  4.88498131e-15,  1.00000000e+00,\n",
       "        7.54951657e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        4.44089210e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "       -2.66453526e-15,  1.00000000e+00,  1.00000000e+00, -2.66453526e-15,\n",
       "        2.00000000e+00,  3.55271368e-15,  1.00000000e+00,  1.77635684e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.77635684e-15,  1.95399252e-14,  1.00000000e+00,  4.44089210e-15,\n",
       "        2.22044605e-15,  6.66133815e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        4.44089210e-16,  1.00000000e+00,  1.15463195e-14,  1.62092562e-14,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.68753900e-14,  1.88737914e-14,  1.99840144e-14,  8.99280650e-15,\n",
       "        6.43929354e-15,  6.43929354e-15,  6.88338275e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -8.65973959e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.28785871e-14, -4.88498131e-15,  5.10702591e-15,  1.00000000e+00,\n",
       "        0.00000000e+00,  2.66453526e-15,  1.00000000e+00, -6.21724894e-15,\n",
       "        1.00000000e+00,  0.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  5.99520433e-15,  7.99360578e-15,  7.54951657e-15,\n",
       "        8.65973959e-15, -6.66133815e-16, -3.10862447e-15, -3.77475828e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  5.32907052e-15,\n",
       "        7.32747196e-15,  8.65973959e-15,  1.00000000e+00,  1.77635684e-15,\n",
       "        1.66533454e-15,  2.66453526e-15,  4.44089210e-15,  4.44089210e-15,\n",
       "        4.88498131e-15,  3.99680289e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.66453526e-15,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "       -2.22044605e-16,  1.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n",
       "        1.00000000e+00,  5.77315973e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00, -1.33226763e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00, -8.88178420e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "       -8.88178420e-16,  2.00000000e+00,  6.21724894e-15,  1.00000000e+00,\n",
       "        1.11022302e-14,  7.99360578e-15,  8.21565038e-15,  1.00000000e+00,\n",
       "        1.00000000e+00, -2.22044605e-15,  1.00000000e+00,  4.44089210e-15,\n",
       "        1.32116540e-14,  1.06581410e-14,  9.99200722e-15,  1.11022302e-14,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.46549439e-14,\n",
       "        1.00000000e+00,  1.13242749e-14,  1.24344979e-14,  1.00000000e+00,\n",
       "        6.66133815e-16,  1.00000000e+00,  1.11022302e-16,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.44249065e-15,  2.66453526e-15,\n",
       "        2.10942375e-15,  3.77475828e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  1.00000000e+00,  4.66293670e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  8.88178420e-16,\n",
       "        1.00000000e+00,  2.22044605e-16,  3.99680289e-15,  1.00000000e+00,\n",
       "        5.32907052e-15,  1.55431223e-15])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1., 2., 2., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 2., 2., 2., 1.,\n",
       "       2., 3., 3., 3., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_entropy(G11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "simplex\n",
      "=======\n",
      "\n",
      "Minimize a linear objective function subject to linear equality and\n",
      "non-negativity constraints using the two phase simplex method.\n",
      "Linear programming is intended to solve problems of the following form:\n",
      "\n",
      "Minimize::\n",
      "\n",
      "    c @ x\n",
      "\n",
      "Subject to::\n",
      "\n",
      "    A @ x == b\n",
      "        x >= 0\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "c : 1D array\n",
      "    Coefficients of the linear objective function to be minimized.\n",
      "c0 : float\n",
      "    Constant term in objective function due to fixed (and eliminated)\n",
      "    variables. (Purely for display.)\n",
      "A : 2D array\n",
      "    2D array such that ``A @ x``, gives the values of the equality\n",
      "    constraints at ``x``.\n",
      "b : 1D array\n",
      "    1D array of values representing the right hand side of each equality\n",
      "    constraint (row) in ``A``.\n",
      "callback : callable, optional (simplex only)\n",
      "    If a callback function is provided, it will be called within each\n",
      "    iteration of the simplex algorithm. The callback must require a\n",
      "    `scipy.optimize.OptimizeResult` consisting of the following fields:\n",
      "\n",
      "        x : 1D array\n",
      "            The independent variable vector which optimizes the linear\n",
      "            programming problem.\n",
      "        fun : float\n",
      "            Value of the objective function.\n",
      "        success : bool\n",
      "            True if the algorithm succeeded in finding an optimal solution.\n",
      "        slack : 1D array\n",
      "            The values of the slack variables. Each slack variable\n",
      "            corresponds to an inequality constraint. If the slack is zero,\n",
      "            the corresponding constraint is active.\n",
      "        con : 1D array\n",
      "            The (nominally zero) residuals of the equality constraints, that\n",
      "            is, ``b - A_eq @ x``\n",
      "        phase : int\n",
      "            The phase of the optimization being executed. In phase 1 a basic\n",
      "            feasible solution is sought and the T has an additional row\n",
      "            representing an alternate objective function.\n",
      "        status : int\n",
      "            An integer representing the exit status of the optimization::\n",
      "\n",
      "                 0 : Optimization terminated successfully\n",
      "                 1 : Iteration limit reached\n",
      "                 2 : Problem appears to be infeasible\n",
      "                 3 : Problem appears to be unbounded\n",
      "                 4 : Serious numerical difficulties encountered\n",
      "\n",
      "        nit : int\n",
      "            The number of iterations performed.\n",
      "        message : str\n",
      "            A string descriptor of the exit status of the optimization.\n",
      "Options\n",
      "-------\n",
      "maxiter : int\n",
      "   The maximum number of iterations to perform.\n",
      "disp : bool\n",
      "    If True, print exit status message to sys.stdout\n",
      "tol : float\n",
      "    The tolerance which determines when a solution is \"close enough\" to\n",
      "    zero in Phase 1 to be considered a basic feasible solution or close\n",
      "    enough to positive to serve as an optimal solution.\n",
      "bland : bool\n",
      "    If True, use Bland's anti-cycling rule [3]_ to choose pivots to\n",
      "    prevent cycling. If False, choose pivots which should lead to a\n",
      "    converged solution more quickly. The latter method is subject to\n",
      "    cycling (non-convergence) in rare instances.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "x : 1D array\n",
      "    Solution vector.\n",
      "status : int\n",
      "    An integer representing the exit status of the optimization::\n",
      "\n",
      "     0 : Optimization terminated successfully\n",
      "     1 : Iteration limit reached\n",
      "     2 : Problem appears to be infeasible\n",
      "     3 : Problem appears to be unbounded\n",
      "     4 : Serious numerical difficulties encountered\n",
      "\n",
      "message : str\n",
      "    A string descriptor of the exit status of the optimization.\n",
      "iteration : int\n",
      "    The number of iterations taken to solve the problem.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] Dantzig, George B., Linear programming and extensions. Rand\n",
      "       Corporation Research Study Princeton Univ. Press, Princeton, NJ,\n",
      "       1963\n",
      ".. [2] Hillier, S.H. and Lieberman, G.J. (1995), \"Introduction to\n",
      "       Mathematical Programming\", McGraw-Hill, Chapter 4.\n",
      ".. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n",
      "       Mathematics of Operations Research (2), 1977: pp. 103-107.\n",
      "\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The expected problem formulation differs between the top level ``linprog``\n",
      "module and the method specific solvers. The method specific solvers expect a\n",
      "problem in standard form:\n",
      "\n",
      "Minimize::\n",
      "\n",
      "    c @ x\n",
      "\n",
      "Subject to::\n",
      "\n",
      "    A @ x == b\n",
      "        x >= 0\n",
      "\n",
      "Whereas the top level ``linprog`` module expects a problem of form:\n",
      "\n",
      "Minimize::\n",
      "\n",
      "    c @ x\n",
      "\n",
      "Subject to::\n",
      "\n",
      "    A_ub @ x <= b_ub\n",
      "    A_eq @ x == b_eq\n",
      "     lb <= x <= ub\n",
      "\n",
      "where ``lb = 0`` and ``ub = None`` unless set in ``bounds``.\n",
      "\n",
      "The original problem contains equality, upper-bound and variable constraints\n",
      "whereas the method specific solver requires equality constraints and\n",
      "variable non-negativity.\n",
      "\n",
      "``linprog`` module converts the original problem to standard form by\n",
      "converting the simple bounds to upper bound constraints, introducing\n",
      "non-negative slack variables for inequality constraints, and expressing\n",
      "unbounded variables as the difference between two non-negative variables.\n",
      "\n",
      "interior-point\n",
      "==============\n",
      "\n",
      "Minimize a linear objective function subject to linear\n",
      "equality and non-negativity constraints using the interior point method\n",
      "of [4]_. Linear programming is intended to solve problems\n",
      "of the following form:\n",
      "\n",
      "Minimize::\n",
      "\n",
      "    c @ x\n",
      "\n",
      "Subject to::\n",
      "\n",
      "    A @ x == b\n",
      "        x >= 0\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "c : 1D array\n",
      "    Coefficients of the linear objective function to be minimized.\n",
      "c0 : float\n",
      "    Constant term in objective function due to fixed (and eliminated)\n",
      "    variables. (Purely for display.)\n",
      "A : 2D array\n",
      "    2D array such that ``A @ x``, gives the values of the equality\n",
      "    constraints at ``x``.\n",
      "b : 1D array\n",
      "    1D array of values representing the right hand side of each equality\n",
      "    constraint (row) in ``A``.\n",
      "\n",
      "Options\n",
      "-------\n",
      "maxiter : int (default = 1000)\n",
      "    The maximum number of iterations of the algorithm.\n",
      "disp : bool (default = False)\n",
      "    Set to ``True`` if indicators of optimization status are to be printed\n",
      "    to the console each iteration.\n",
      "tol : float (default = 1e-8)\n",
      "    Termination tolerance to be used for all termination criteria;\n",
      "    see [4]_ Section 4.5.\n",
      "alpha0 : float (default = 0.99995)\n",
      "    The maximal step size for Mehrota's predictor-corrector search\n",
      "    direction; see :math:`\\beta_{3}` of [4]_ Table 8.1.\n",
      "beta : float (default = 0.1)\n",
      "    The desired reduction of the path parameter :math:`\\mu` (see [6]_)\n",
      "    when Mehrota's predictor-corrector is not in use (uncommon).\n",
      "sparse : bool (default = False)\n",
      "    Set to ``True`` if the problem is to be treated as sparse after\n",
      "    presolve. If either ``A_eq`` or ``A_ub`` is a sparse matrix,\n",
      "    this option will automatically be set ``True``, and the problem\n",
      "    will be treated as sparse even during presolve. If your constraint\n",
      "    matrices contain mostly zeros and the problem is not very small (less\n",
      "    than about 100 constraints or variables), consider setting ``True``\n",
      "    or providing ``A_eq`` and ``A_ub`` as sparse matrices.\n",
      "lstsq : bool (default = False)\n",
      "    Set to ``True`` if the problem is expected to be very poorly\n",
      "    conditioned. This should always be left ``False`` unless severe\n",
      "    numerical difficulties are encountered. Leave this at the default\n",
      "    unless you receive a warning message suggesting otherwise.\n",
      "sym_pos : bool (default = True)\n",
      "    Leave ``True`` if the problem is expected to yield a well conditioned\n",
      "    symmetric positive definite normal equation matrix\n",
      "    (almost always). Leave this at the default unless you receive\n",
      "    a warning message suggesting otherwise.\n",
      "cholesky : bool (default = True)\n",
      "    Set to ``True`` if the normal equations are to be solved by explicit\n",
      "    Cholesky decomposition followed by explicit forward/backward\n",
      "    substitution. This is typically faster for moderate, dense problems\n",
      "    that are numerically well-behaved.\n",
      "pc : bool (default = True)\n",
      "    Leave ``True`` if the predictor-corrector method of Mehrota is to be\n",
      "    used. This is almost always (if not always) beneficial.\n",
      "ip : bool (default = False)\n",
      "    Set to ``True`` if the improved initial point suggestion due to [4]_\n",
      "    Section 4.3 is desired. Whether this is beneficial or not\n",
      "    depends on the problem.\n",
      "permc_spec : str (default = 'MMD_AT_PLUS_A')\n",
      "    (Has effect only with ``sparse = True``, ``lstsq = False``, ``sym_pos =\n",
      "    True``.) A matrix is factorized in each iteration of the algorithm.\n",
      "    This option specifies how to permute the columns of the matrix for\n",
      "    sparsity preservation. Acceptable values are:\n",
      "\n",
      "    - ``NATURAL``: natural ordering.\n",
      "    - ``MMD_ATA``: minimum degree ordering on the structure of A^T A.\n",
      "    - ``MMD_AT_PLUS_A``: minimum degree ordering on the structure of A^T+A.\n",
      "    - ``COLAMD``: approximate minimum degree column ordering.\n",
      "\n",
      "    This option can impact the convergence of the\n",
      "    interior point algorithm; test different values to determine which\n",
      "    performs best for your problem. For more information, refer to\n",
      "    ``scipy.sparse.linalg.splu``.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "x : 1D array\n",
      "    Solution vector.\n",
      "status : int\n",
      "    An integer representing the exit status of the optimization::\n",
      "\n",
      "     0 : Optimization terminated successfully\n",
      "     1 : Iteration limit reached\n",
      "     2 : Problem appears to be infeasible\n",
      "     3 : Problem appears to be unbounded\n",
      "     4 : Serious numerical difficulties encountered\n",
      "\n",
      "message : str\n",
      "    A string descriptor of the exit status of the optimization.\n",
      "iteration : int\n",
      "    The number of iterations taken to solve the problem.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "This method implements the algorithm outlined in [4]_ with ideas from [8]_\n",
      "and a structure inspired by the simpler methods of [6]_ and [4]_.\n",
      "\n",
      "The primal-dual path following method begins with initial 'guesses' of\n",
      "the primal and dual variables of the standard form problem and iteratively\n",
      "attempts to solve the (nonlinear) Karush-Kuhn-Tucker conditions for the\n",
      "problem with a gradually reduced logarithmic barrier term added to the\n",
      "objective. This particular implementation uses a homogeneous self-dual\n",
      "formulation, which provides certificates of infeasibility or unboundedness\n",
      "where applicable.\n",
      "\n",
      "The default initial point for the primal and dual variables is that\n",
      "defined in [4]_ Section 4.4 Equation 8.22. Optionally (by setting initial\n",
      "point option ``ip=True``), an alternate (potentially improved) starting\n",
      "point can be calculated according to the additional recommendations of\n",
      "[4]_ Section 4.4.\n",
      "\n",
      "A search direction is calculated using the predictor-corrector method\n",
      "(single correction) proposed by Mehrota and detailed in [4]_ Section 4.1.\n",
      "(A potential improvement would be to implement the method of multiple\n",
      "corrections described in [4]_ Section 4.2.) In practice, this is\n",
      "accomplished by solving the normal equations, [4]_ Section 5.1 Equations\n",
      "8.31 and 8.32, derived from the Newton equations [4]_ Section 5 Equations\n",
      "8.25 (compare to [4]_ Section 4 Equations 8.6-8.8). The advantage of\n",
      "solving the normal equations rather than 8.25 directly is that the\n",
      "matrices involved are symmetric positive definite, so Cholesky\n",
      "decomposition can be used rather than the more expensive LU factorization.\n",
      "\n",
      "With the default ``cholesky=True``, this is accomplished using\n",
      "``scipy.linalg.cho_factor`` followed by forward/backward substitutions\n",
      "via ``scipy.linalg.cho_solve``. With ``cholesky=False`` and\n",
      "``sym_pos=True``, Cholesky decomposition is performed instead by\n",
      "``scipy.linalg.solve``. Based on speed tests, this also appears to retain\n",
      "the Cholesky decomposition of the matrix for later use, which is beneficial\n",
      "as the same system is solved four times with different right hand sides\n",
      "in each iteration of the algorithm.\n",
      "\n",
      "In problems with redundancy (e.g. if presolve is turned off with option\n",
      "``presolve=False``) or if the matrices become ill-conditioned (e.g. as the\n",
      "solution is approached and some decision variables approach zero),\n",
      "Cholesky decomposition can fail. Should this occur, successively more\n",
      "robust solvers (``scipy.linalg.solve`` with ``sym_pos=False`` then\n",
      "``scipy.linalg.lstsq``) are tried, at the cost of computational efficiency.\n",
      "These solvers can be used from the outset by setting the options\n",
      "``sym_pos=False`` and ``lstsq=True``, respectively.\n",
      "\n",
      "Note that with the option ``sparse=True``, the normal equations are solved\n",
      "using ``scipy.sparse.linalg.spsolve``. Unfortunately, this uses the more\n",
      "expensive LU decomposition from the outset, but for large, sparse problems,\n",
      "the use of sparse linear algebra techniques improves the solve speed\n",
      "despite the use of LU rather than Cholesky decomposition. A simple\n",
      "improvement would be to use the sparse Cholesky decomposition of\n",
      "``CHOLMOD`` via ``scikit-sparse`` when available.\n",
      "\n",
      "Other potential improvements for combatting issues associated with dense\n",
      "columns in otherwise sparse problems are outlined in [4]_ Section 5.3 and\n",
      "[10]_ Section 4.1-4.2; the latter also discusses the alleviation of\n",
      "accuracy issues associated with the substitution approach to free\n",
      "variables.\n",
      "\n",
      "After calculating the search direction, the maximum possible step size\n",
      "that does not activate the non-negativity constraints is calculated, and\n",
      "the smaller of this step size and unity is applied (as in [4]_ Section\n",
      "4.1.) [4]_ Section 4.3 suggests improvements for choosing the step size.\n",
      "\n",
      "The new point is tested according to the termination conditions of [4]_\n",
      "Section 4.5. The same tolerance, which can be set using the ``tol`` option,\n",
      "is used for all checks. (A potential improvement would be to expose\n",
      "the different tolerances to be set independently.) If optimality,\n",
      "unboundedness, or infeasibility is detected, the solve procedure\n",
      "terminates; otherwise it repeats.\n",
      "\n",
      "The expected problem formulation differs between the top level ``linprog``\n",
      "module and the method specific solvers. The method specific solvers expect a\n",
      "problem in standard form:\n",
      "\n",
      "Minimize::\n",
      "\n",
      "    c @ x\n",
      "\n",
      "Subject to::\n",
      "\n",
      "    A @ x == b\n",
      "        x >= 0\n",
      "\n",
      "Whereas the top level ``linprog`` module expects a problem of form:\n",
      "\n",
      "Minimize::\n",
      "\n",
      "    c @ x\n",
      "\n",
      "Subject to::\n",
      "\n",
      "    A_ub @ x <= b_ub\n",
      "    A_eq @ x == b_eq\n",
      "     lb <= x <= ub\n",
      "\n",
      "where ``lb = 0`` and ``ub = None`` unless set in ``bounds``.\n",
      "\n",
      "The original problem contains equality, upper-bound and variable constraints\n",
      "whereas the method specific solver requires equality constraints and\n",
      "variable non-negativity.\n",
      "\n",
      "``linprog`` module converts the original problem to standard form by\n",
      "converting the simple bounds to upper bound constraints, introducing\n",
      "non-negative slack variables for inequality constraints, and expressing\n",
      "unbounded variables as the difference between two non-negative variables.\n",
      "\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n",
      "       optimizer for linear programming: an implementation of the\n",
      "       homogeneous algorithm.\" High performance optimization. Springer US,\n",
      "       2000. 197-232.\n",
      ".. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n",
      "       Programming based on Newton's Method.\" Unpublished Course Notes,\n",
      "       March 2004. Available 2/25/2017 at\n",
      "       https://ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n",
      ".. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n",
      "       programming.\" Mathematical Programming 71.2 (1995): 221-245.\n",
      ".. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n",
      "       programming.\" Athena Scientific 1 (1997): 997.\n",
      ".. [10] Andersen, Erling D., et al. Implementation of interior point methods\n",
      "        for large scale linear programming. HEC/Universite de Geneve, 1996.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.optimize.show_options('linprog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1., 2., 2., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 2., 2., 2., 1.,\n",
    "       2., 3., 3., 3., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_approx_identical_entropy(G1, G2):\n",
    "    entropy_g1 = lp_entropy(G1)\n",
    "    entropy_g2 = lp_entropy(G2)\n",
    "    return np.array_equal(np.round(entropy_g1.x), np.round(entropy_g2.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(G):\n",
    "    nx_G = nx.from_dict_of_lists(G)\n",
    "    nx.draw_networkx(nx_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "G1 = {1:{2,3,4,5}, 2:{1,3}, 3:{1,2}, 4: {1,5}, 5:{1,4}}\n",
    "draw_graph(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4FFXW+PHvZQ8qCIICQgReFcUsLCFssioQILKZ+OL2oqBoVMYZRUfGBfXniAvqjKMkiGBAkZGEJWENZAMlLCFCEkBWQRaFsARQSCDL/f3RndiEDklIdVcv5/M8/aS7+nbVoRJOVd86da/SWiOEEMK71DA7ACGEEM4nyV8IIbyQJH8hhPBCkvyFEMILSfIXQggvJMlfCCG8kCR/IYTwQpL8hRDCC0nyF0IIL1TL7ADK06RJE926dWuzwxBCCLeSkZFxQmvdtKJ2Lpv8W7duzebNm80OQwgh3IpS6pfKtJNuHyGE8EKS/IUQwgtJ8hdCCC8kyV8IIbyQJH8hhPBCkvyFEMILSfIXQggv5LJ1/kII4dFyciA6GrKy4MwZaNgQAgLg8cehaYX3aFWbJH8hhHCm9HSYMgVWrLC8zs//872FC2HyZBg8GCZNgi5dHBaGdPsIIYSzREZC376weLEl6dsmfoC8PMuyxYst7SIjHRaKIclfKRWilNqllNqrlHqlnDYPKKV2KKW2K6W+NWK7QgjhNiIjYeJEOH8etAagL1APuNb6aFfSVmtLu4kTHXYAqHbyV0rVBD4HBgPtgQeVUu3LtLkNmAT01FrfBfy1utsVQgi3kZ7+Z+Iv4zPgD+tjV9k3Sw4ADhjnzIgz/2Bgr9b6Z631ReC/wPAybZ4EPtda5wJorXMM2K4QQriHKVMsXTpXIy/P8nmDGZH8bwYO2bw+bF1m63bgdqXUOqXUBqVUiL0VKaXGK6U2K6U2Hz9+3IDQhBDCZDk5lou71q6esiYBTYCeQKq9BlrD8uVgcE40IvkrO8vK/itrAbdh6eJ6EPhSKXX9ZR/S+gutdZDWOqipE0qdhBDC4aKjy33rfeBn4AgwHrgP2GevoVJXXM/VMCL5HwZa2bxuCfxqp02c1rpAa70fS9fWbQZsWwghXFtW1uVVPVZdgeuAusAYLGf/y+01zMuD7GxDwzIi+acDtyml2iil6gCjgfgybRYD/QCUUk2wdAP9bMC2hRDCtZ05U+mmisu7TUrl5hoRTalqJ3+tdSHwHJAA/ATM11pvV0q9rZQaZm2WAJxUSu0AUoCXtNYnq7ttIYRweQ0b2l18GktizAcKgbnAWmBQeetp1MjQsAy5w1drvZwy31a01m/YPNfAC9aHEEJ4hW3btrFn3z5CAJ8y7xUArwE7gZrAHVi6SNphh48P+PsbGpvc4SuEEAa6cOEC8+bNo3fv3gwcOJA9PXtSr27dy9o1xdJn/juWbwEbgAHlrVRreOwxQ+OUsX2EEMIABw4cYPr06cyaNQs/Pz+ef/55hg0bRu3ateHnny1DNpRT7nlFSsGQIYYP9iZn/kIIcZWKiopYtmwZoaGhBAUFkZ+fz9q1a0lKSuL++++3JH6wDNLmU7bjp5J8fCyfN5ic+QshRBXl5OQwc+ZMpk+fzo033khERATz58+nfv369j/QpQtMnVruEA/lql/f8rmgIGMCtyHJXwghKkFrzQ8//MC0adNYuXIlo0aNIjY2lqDKJuaICMvPiRPReXmoK3UBKWU545869c/PGUy6fYQQ4grOnj3L559/jr+/P08++STdunXj559/ZubMmZVP/CUiImDNGvb5+3OxZs3Lu4J8fKBePRg5EtascVjiBznzF0IIu7Zu3UpkZCTz58/n3nvv5dNPP6Vfv34oZW9EmyoICuKpJk2YOGsWg48ds9y5m5trqeP397dU9chMXkII4Tz5+fnExMQQGRnJoUOHGD9+PDt27KB58+aGbSM3N5f09HR6x8fDNdcYtt6qkuQvhPB6+/btIyoqiujoaDp16sTLL79MaGgotWoZnyJXrFhBnz59uMbExA/S5y+E8FKFhYXExcUREhJCt27dAFi/fj0JCQmMGDHCIYkfID4+nuHDy0554nxy5i+E8CpHjx7lyy+/5IsvvuDmm28mIiKCRYsW4XO1dfhVcPHiRRISEvjXv/7l8G1VRJK/EMLjaa1JTU0lMjKS1atX88ADDxAfH0+HDh2cGseaNWto164dzZo1c+p27ZHkL4TwWKdPn2bOnDlERUWhlCIiIoIZM2bQsJyRNh3NVbp8QJK/EMIDZWRkEBkZyYIFCxg0aBBRUVH06tWr+mWa1aC1Jj4+nuXL7U7X4nSS/IUQHiEvL4/vvvuOyMhIjh49ylNPPcXOnTu56aabzA4NgMzMTGrXrk379u3NDgWQ5C+EcHO7d+8mKiqKOXPmEBwczOuvv87gwYOpWbOm2aFdIj4+nmHDhpn67cOWlHoKIdxOYWEhCxcuZMCAAfTq1Ys6deqQnp7O8uXLCQ0NdbnEDxAXF8ewYcMqbugkcuYvhHAbR44cYcaMGcyYMYO2bdsSERHB/fffT107k6W4ksOHD3PgwAHuvvtus0MpJclfCOHSiouLSU5OJjIykpSUFEaPHs3KlSvxN3haQ0dasmQJQ4YMcdiNY1fDdSIRQggbp06dIjo6mqioKHx8fIiIiCA6OprrrrvO7NCqLC4ujnHjxpkdxiUk+QshXIbWmvT0dKZNm8bixYsJDQ3lq6++okePHi5zobSqzp49y7p164iJiTE7lEtI8hdCmO7cuXPMmzePyMhIcnNzefrpp/nwww9p6oShjR1t1apV9OzZ0+W+sUjyF0KY5qeffiIyMpK5c+fSs2dP3nnnHQYNGkSNGp5TiOhqVT4lPGcPCyHcwsWLF5k/fz79+vWjf//+NGjQgC1bthAfH8/gwYM9KvEXFhayfPlyl0z+cuYvhHCKgwcP8sUXXzBz5kzatWtHREQEI0eOpE6dOmaH5jDr1q2jdevWtGzZ0uxQLuM5h1ghhMspLi5m5cqVDB8+nA4dOnD27FmSkpJITU3lf//3fz068YOly8dVBnIrS878hRCGO3HiBLNmzWL69Ok0bNiQiIgI5s6dy7XXXmt2aE5TMpBbbGys2aHYZciZv1IqRCm1Sym1Vyn1yhXahSmltFKqilPeCyFcndaatLQ0Hn30UW699Va2b9/Ot99+S0ZGBk8++aRXJX6AHTt2UFBQQGBgoNmh2FXtM3+lVE3gc2AAcBhIV0rFa613lGl3HfAXYGN1tymEcB1//PEHc+fOZdq0aZw/f56nn36af/3rX9xwww1mh2YqVxvIrSwjzvyDgb1a65+11heB/wL2Orn+H/ABkG/ANoUQJtu2bRvPPvssvr6+rFy5kqlTp7Jr1y5efPFFr0/88Gfyd1VGJP+bgUM2rw9bl5VSSnUEWmmtlxqwPSGESS5cuMC8efPo3bs3AwcOpEmTJmRlZbFo0SIGDBjgUWWa1XH06FF27txJnz59zA6lXEZc8LX3nUaXvqlUDeAT4LEKV6TUeGA8gK+vrwGhCSGMcODAAaZPn86sWbPw8/Pj+eefZ9iwYdSuXdvs0FzS0qVLGTRokEtXMxlxmD4MtLJ53RL41eb1dYAfkKqUOgB0A+LtXfTVWn+htQ7SWgd5wm3dQrizoqIili1bRmhoKEFBQeTn57N27VqSkpK4//77JfFfgat3+YAxZ/7pwG1KqTbAEWA08FDJm1rrM0CTktdKqVRgotZ6swHbFkIYLCcnh5kzZzJ9+nRuvPFGIiIimD9/PvXr1zc7NLdw7tw5UlNTmT17ttmhXFG1k7/WulAp9RyQANQEZmmttyul3gY2a63jq7sNIYRjaa354YcfmDZtGitXrmTUqFHExsYSFCRV2VWVmJhIly5daNSokdmhXJEhN3lprZcDy8sse6Octn2N2KYQovrOnj3L119/TWRkJIWFhURERDBt2jSXT1yuzFUHcitLLs0L4YW2bt3KU089xS233EJqaiqffvopP/30E88//7wk/mooKipi6dKlbpH8ZXgHIbxEfn4+MTExREZGcujQIcaPH8+OHTto3ry52aF5jI0bN9KsWTPatGljdigVkuQvhIfbt28fUVFRREdH06lTJ15++WVCQ0Ndaj5ZT+EuXT4g3T5CeKTCwkLi4uIICQmhW7duAKxfv56EhARGjBghid9B4uPjXXYUz7LkL0AID/Lbb7/x5ZdfMmPGDG6++WYiIiJYtGgRPj4+Zofm8Xbv3s2ZM2fo3Lmz2aFUiiR/Idyc1prU1FQiIyNZvXo14eHhxMXF0bFjR7ND8yrx8fHcd999bjPEhSR/IdzU6dOnmT17NlFRUdSoUYOIiAhmzJhBw4YNzQ7NK8XHx/PKK+WOaO9yJPkL4WYyMjKIjIxkwYIFDBo0iOnTp9OrVy+XHTrYG5w4cYLMzEz69+9vdiiVJslfCDdw/vx5vvvuOyIjIzl27BhPPfUUO3fu5KabbjI7NAEsW7aMe+65h3r16pkdSqVJ8hfChe3evZuoqCjmzJlDcHAwb7zxBoMHD6ZmzZpmhyZsuFOVTwn3uDIhhBcpKChgwYIF3HvvvfTq1Ys6deqQnp7O8uXLCQ0NlcTvYvLz80lMTGTo0KFmh1IlcuYvhIs4cuQIM2bMYMaMGbRt25aIiAjuv/9+6tata3Zo4gqSk5MJDAykSZMmFTd2IZL8hTBRcXExycnJREZGkpKSwujRo1m5ciX+/v5mhyYqyR3G7rdHkr8QFcnJgehoyMqCM2egYUMICIDHH4ernHTo1KlTREdHExUVhY+PDxEREURHR3PdddcZG7twqOLiYuLj40lNTTU7lCqT5C9EedLTYcoUWLHC8jo//8/3Fi6EyZNh8GCYNAm6dKlwdVpr0tPTmTZtGosXLyY0NJSvvvqKHj16SJmmm8rIyKBhw4bcfvvtZodSZXLBVwh7IiOhb19YvNiS9G0TP0BenmXZ4sWWdpGR5a7q3LlzfPnllwQFBTF69Gjat2/Pnj17+Oabb+jZs6ckfjfmrl0+IGf+QlwuMhImToTz5ytuq7Wl3cSJltcREaVv/fTTT0RGRjJ37lx69uzJO++8w6BBg9zm9n9Rsbi4OCKvcOB3ZZL8hbCVnm438X8GRAPZwIPW55ewHgAKOnRg0aFDREZGsnPnTsaNG8eWLVvw9fV1QvDCmfbv38/Ro0dLR011N5L8hbA1ZYqlS6eMFsBrWCaqvvxdi+Lz51nVrx/TunUjIiKCkSNHUqdOHQcGK8y0ZMkSt77vQpK/ECVyciwXd7W+7K1R1p+bgcPlfLwGMFhrhsbEXHUVkHAfcXFx/OUvfzE7jKsmnY9ClIiOrvYqatSsach6hGvLzc0lPT2de++91+xQrpokfyFKZGVdXtVTVXl5kJ1tTDzCZa1YsYI+ffpwzTXXmB3KVZPkL0SJM2eMWU9urjHrES7LHQdyK0uSvxAljJoEpVEjY9YjXNLFixdJSEggNDTU7FCqRZK/ECUCAqCc8dgLgXygyPrIty67jI8PyLg8Hm3NmjW0a9eOZs2amR1KtUjyF6LEY4+V+9Y7gA/wHvCN9fk79hpqfcX1CPfnCV0+IMlfiFJ/1K9PZosWFNl5701Al3m8WaZNsVIwZIiUeXowrbVbD+lgS5K/EEBSUhL+/v4svvNOavj4XNU68oGP6tQhz85NYsIzZGZmUqtWLdq3b292KNVmSPJXSoUopXYppfYqpS6bvl4p9YJSaodSKksplaSUusWI7QpRXWfOnOHJJ59k7NixTJs2jclLl6I++gjq16/aiurXR3/4IelaExQUxNatWx0TsDBVSZePJwzGV+3kr5SqCXwODAbaAw8qpcoeFrcAQVrrACAW+KC62xWiupYuXYqfnx+1atUiOzubwYMHW96IiICpUy0HgIr+kytlaTd1Kte8+CLz5s3jH//4BwMHDuT999+nqMheJ5JwV57S5QNY+rCq8wC6Awk2rycBk67QviOwrqL1du7cWQvhCCdOnNAPP/ywbtu2rU5OTi6/YXq61qNG6Qs1auiC2rW1tlzOtTx8fLSuV0/rUaMs7cr45ZdfdN++fXWvXr30/v37HfePEU5z6NAh3bhxY11QUGB2KFcEbNaVyN1GdPvcDByyeX3Yuqw844AVBmxXiCqLjY3Fz8+PG2+8kaysLPr161d+46AgiubPx69BA879/e/w6KMQGmr5+dZbcPAgLFgAQUGXfdTX15ekpCSGDRtGcHAwX3/9dcnJj3BTS5YsYciQIdSq5RlDohnxr7D3vdjuX7lS6hEgCOhTzvvjgfGADIErDHX06FGeffZZduzYwcKFC+nevXulPpeZmUnNZs1o+P/+X5W3WaNGDSZOnMiAAQN4+OGHWbJkCVFRUTRu3LjK6xLmi4uLY9y4cWaHYRgjzvwPA61sXrcEfi3bSCl1L/AqMExrfcHeirTWX2itg7TWQU2lXE4YQGvNnDlzCAwM5I477mDLli2VTvwAycnJ9O/fv1oxBAYGsnnzZlq2bElgYCCrV6+u1vqE8509e5Z169YREhJidiiGMeLMPx24TSnVBjgCjAYesm2glOoITAdCtNY5BmxTiAodOnSIp556il9//ZUVK1bQqVOnKq8jKSmJJ598stqx1KtXj48//pihQ4fy+OOPM3LkSN577z18rrKsVDjXqlWr6NmzJ9ddd53ZoRim2mf+WutC4Dks81z8BMzXWm9XSr2tlCq5LP4hcC0Qo5TaqpSKr+52hShPcXEx06dPp1OnTvTo0YP09PSrSvwXL15k3bp19Oljt5fyqtxzzz1kZmaSk5NDUFAQW7ZsMWzdwnHi4uI8p8qnRGWuCpvxkGofcTX27dun+/Xrp4ODg/W2bduqta4ffvhBd+zY0aDILjd37lzdtGlT/d577+nCwkKHbUdUT0FBgW7cuLE+dOiQ2aFUCk6s9hHCdEVFRfz73/8mODiYoUOHkpaWxl133VWtdSYlJXHPPfcYFOHlHnroITZv3szKlSvp168fBw4ccNi2xNVbt24drVu3pmXLlmaHYihJ/sLt7dy5k169erFw4ULWr1/Piy++aMi8qkZc7K1I2ZLQOXPmSEmoi/HILh8k+Qs3VlhYyJQpU+jVqxePPPIIKSkp3HbbbYas+/z582zevJlevXoZsr4rKSkJTUxM5MMPP+SBBx7g5MmTDt+uqJi2DuTmCaN4liXJX7ilzMxMunbtSkpKCunp6TzzzDPUqGHcn/O6devo0KED1157rWHrrEhAQADp6en4+voSGBjIqlWrnLZtYd+OHTsoKCggMDDQ7FAMJ8lfuJULFy7wxhtvMGDAAJ577jkSEhJo3bq14dtxRpePPfXq1eOjjz5i9uzZPPHEEzz//PMySqiJSsby8YSB3MqS5C/cxqZNm+jcuTOZmZls3bqVxx9/3GH/Kc1K/iWkJNQ1eNRAbmVI8hcuLy8vj5deeolhw4bx2muvsXjxYlq0aOGw7Z0+fZodO3ZU6U5gR2jUqBHz5s3j1VdfZdCgQbz33nsySqgTHT16lJ07dxp6n4crkeQvXNr3339PYGAghw8fJjs7m9GjRzv8K/jatWvp1q0bdevWdeh2KqukJDQhIUFKQp1o6dKlDBo0iDp16pgdikNI8hcu6Y8//mDChAmMHj2aDz74gHnz5uGs8Z7M7vKxp6QkdPjw4XTp0kVKQp3Ak7t8QJK/cEGrV6/G39+fc+fOsW3bNkaMGOHU7Tv65q6rVaNGDV588UWSkpKkJNTBzp07R2pq6p8T/HggSf7CZZw+fZpx48bxxBNPEBUVxaxZs2jUqJFTYzh27BiHDh26qrGAnEVKQh0vMTGRLl26OP3vz5kk+QuXEB8fj5+fH3Xr1iU7O5tBgwaZEkdqaiq9e/d2+Qk7SkpC58yZwxNPPMFf/vIXKQk1kKd3+YAkf2GyEydO8NBDD/HCCy8wd+5cpk2bRoMGDUyLx1W7fMrTv39/MjMzOXHiBJ07d+bHH380OyS3V1RUxNKlSyX5C+EIWmvmz5+Pv78/LVq0ICsryyVK6lzxYm9FGjVqxLfffstrr71GSEiIlIRW08aNG7npppto06aN2aE4lCR/4XS//fYbo0aN4s0332TRokVMnTqV+vXrmx0Wv/zyC2fPnq32aKBmkZJQY3jqQG5lSfIXTqO1Jjo6msDAQPz8/NiyZQvdunUzO6xSJWf9Ro4R5Gy2JaHBwcHMnj1bSkKryFMHcivLta9qCY9x8OBBxo8fz7Fjx0hISKBjx45mh3QZd+zysaekJNR24vjp06dzww03mB2ay9u9ezdnzpyhc+fOZoficO57iiPcQnFxMVFRUXTu3JnevXuzadMml0z8WmuPSf4lSkpCb7nlFikJraT4+Hjuu+8+t/72V1ly5i8cZu/evTzxxBPk5+ezZs0a2rdvb3ZI5dq1axe1atXif/7nf8wOxVAlJaFDhw7lscceY8SIEbz//vsycXw54uPjeeWVV8wOwyk8//AmnK6oqIhPPvmEbt26MWzYMNatW+fSiR/+7PLxxKF7QUpCK+PEiRNkZmZ61Le/K5Ezf2GoHTt2MG7cOOrWrcuGDRu49dZbzQ6pUpKTkz3+Il9JSei3335LSEgIf/vb33j55ZcNmfLSEyxbtox77rmHevXqmR2KU8iZvzBEQUEB7777Ln369GHMmDEkJye7TeIvLi4mNTXVa874SkpCV61aRd++fdm/f7/ZIbkEb6nyKSHJX1Tb1q1bCQ4OZu3atWRkZPD000+71QWzzMxMmjRpws0332x2KE5TUhI6YsQIKQkF8vPzSUxMZOjQoWaH4jTu8z9UuJwLFy7w2muvMXDgQP7617+yYsUKfH19zQ6ryjytyqeybEcJnTp1KuHh4V47SmhycjKBgYE0adLE7FCcRpK/uCobN26kU6dObN++nczMTMaMGeO2F0u9NfmXKFsSmpCQYHZITucNA7ldRmvtko/OnTtr4XrOnTunX3zxRd2sWTP93Xff6eLiYrNDqpaLFy/qBg0a6BMnTpgdiktISkrSrVq10hMmTNDnz583OxynKCoq0s2bN9e7du0yOxRDAJt1JXKsnPmLSluzZg2BgYH89ttvZGdn88ADD7jt2X6J9PR02rZtK3e/WnljSWhGRgYNGzbk9ttvNzsUp5LkLyr0+++/8+yzz/Lwww/z0UcfMXfuXI/pG/X2Lh97yo4SOmXKFI8eJdQru3wwKPkrpUKUUruUUnuVUpfdHqeUqquU+s76/kalVGsjtiscLyEhAT8/P/Lz89m2bZvH/Sdxt/H7namkJHT16tUeXRLqLaN4llXt5K+Uqgl8DgwG2gMPKqXK3s45DsjVWt8KfAK8X93tCsfKzc1l7NixPPXUU8yYMYOZM2dy/fXXmx2WofLy8khPT6dXr15mh+KyfH19SUxMZMSIEXTt2tXjSkL379/P0aNHXWp0WWcx4sw/GNirtf5Za30R+C9Q9k6J4cBs6/NY4B7l7p3FHiwuLg4/Pz/q169PdnY2AwcONDskh0hLSyMgIIDrrrvO7FBcWklJaGJiIh999JFHlYQuWbKE0NBQr7zL2YjkfzNwyOb1Yesyu2201oXAGeCyK2xKqfFKqc1Kqc3Hjx83IDRRFcePH2f06NG89NJLzJs3j88++8yjE6N0+VRNQEAAmzZt8qiSUG/t8gFjkr+9M/iy3wsr0wat9Rda6yCtdVDTpk0NCE1Uhtaa//73v/j7++Pr60tmZia9e/c2OyyHk4u9VWc7cfyTTz7p1hPH5+bmkp6ezoABA8wOxRRGJP/DQCub1y2BX8tro5SqBTQEThmwbVFNv/76KyNHjuSdd94hPj6eDz74wCuG+z1z5gzbt2+ne/fuZofiljyhJHTlypX06dOHa665xuxQTGFE8k8HblNKtVFK1QFGA/Fl2sQDY6zPw4Bk7UlXjdyQ1pqvvvqKDh06EBgYSEZGBsHBwWaH5TRr166la9euXjOCoyOUlIS+/vrrblkSGhcX51UDuZVV7eRv7cN/DkgAfgLma623K6XeVkqVdKbNBG5QSu0FXgC8Y7YEF/XLL78QEhLCf/7zH1avXs1bb71F3bp1zQ7LqaTLxzgPPvggGRkZblUSevHiRRISEggNDTU7FNMYUuevtV6utb5da/0/Wut/Wpe9obWOtz7P11qHa61v1VoHa61/NmK7omqKi4uZNm0aQUFB9O3bl40bNxIYGGh2WKaQ5G+sVq1alZaEusMooWvWrKFdu3Y0a9bM7FBMI5O5eIk9e/bwxBNPUFBQwNq1a7nzzjvNDsk0OTk5/PLLLwQFBZkdikexnTj+kUcecemJ471t7H57ZHgHD1dUVMRHH31E9+7dGTlyJN9//71XJ36A1NRUevXqRa1acu7jCCUloa1bt3bJklCttdcO6WBL/vo92Pbt2xk7dizXXHMNGzdu9LjJya+WdPk4Xr169Zg6dSpDhw5lzJgxDB8+nPfff5/69eubHRqZmZnUqlXL5eeVdjQ58/dABQUFvPPOO/Tt25dx48aRmJgoid+G3NzlPP369SMzM5OTJ0+6TEloSZePtw8yIMnfw/z444906dKFtLQ0fvzxR8aPH+9WUyo62sGDBzl9+jR+fn5mh+I1SkpC33jjDZcoCZUuHwvJCh4iPz+fV199lcGDB/Piiy+ybNkyWrVqVfEHvUxKSgr9+vWTA6IJXKEk9PDhw+zfv5+7777b6dt2NfI/wANs2LCBTp06sXPnTjIzM3n00Ue9/itteaTLx1wlJaEjR44kODiY6Ohop5aELlmyhCFDhsjFfiT5u7Xz58/zwgsvMHLkSN5++20WLFjg1XXLFdFay8VeF1CjRg1eeOEFkpOT+fjjjwkLC+PEiRNO2bY3D+RWliR/N5WSkoK/vz85OTlkZ2cTFhZmdkgub8+ePSiluPXWW80ORQD+/v5s2rSJNm3aOKUk9OzZs6xbt46QkBCHbsddSPJ3M2fPniUiIoL/+7//49///jfffPONx0yp6GglXT7SJeY6SkpCv/nmG8aPH8+ECRM4f/68Q7a1atUqevbs6dHDlFeFJH83smLFCvz8/CgsLCQ7O9urxyW5GtLl47pKSkJPnTrlsJJQ6fIpQ2vtko+dMAW0AAAabklEQVTOnTtrYXHy5Ek9ZswY3bp1a7169Wqzw3FLRUVF+oYbbtAHDx40OxRRgW+//VY3bdpU//Of/9SFhYWGrLOgoEA3btxYHzp0yJD1uTJgs65EjpUzfxe3aNEi/Pz8aNCgAdnZ2dx7771mh+SWsrKyaNy4sZS/uoGSktDExET69OljSEnounXraN26NS1btjQgQs8gyd9F5eTk8MADD/DKK68wf/58Pv30U6699lqzw3JbycnJUuLpRkpKQkeNGmVISah0+VxOkr+L0Vrz7bff4u/vT5s2bdi6davckGIA6e93P0aVhGrrQG7ePopnWXKngws5cuQIERER7N+/n6VLl9KlSxezQ/IIBQUFfP/993z11VdmhyKugr+/P+np6bz22msEBgYyc+bMK5dr5uRAdDRkZcGZM5wBHj9xgsAWLZwVsnuozIUBMx7edMG3uLhYf/nll7pJkyZ68uTJ+sKFC2aH5FHS0tJ0YGCg2WEIAyQnJ2tfX1/97LPP6nPnzl365qZNWo8cqXW9epYHlD4u1KxpWTZypKWdB0Mu+LqHAwcOMHDgQCIjI0lKSuLNN9+kTp06ZoflUaTLx3OUlITm5ubSuXNnMjIyLG9ERkLfvrB4MeTnWx426hQVWZYtXmxpFxnp9NhdjSR/kxQXF/PZZ58RFBTEvffey4YNGwgICDA7LI8kyd+zXH/99cydO5fJkyczePBgVgwfjp44Ec6ft5zn29gD1AMeKVmgtaXdxIlefwCQPn8T7N69m3HjxlFcXMy6deto166d2SF5rLy8PDZu3Ejv3r3NDkUYbPTo0fS79loaDh+OKi622+ZZwO6Vs5IDQJcu4KXTecqZvxMVFhby4Ycf0qNHD8LDw1m7dq0kfgdbv349/v7+NGjQwOxQhAPcNGsWdcspAf0vcD1QboFvXh5MmeKgyFyfnPk7SXZ2NmPHjqVBgwZs2rSJtm3bmh2SV5AuHw+WkwMrVqDsJP+zwBtAEjCzvM9rDcuXw/Hj0LSp4+J0UXLm72AXL17k7bffpn///owfP57ExERJ/E4k4/d7sOjoct96HRgHVHg/t1JXXI8nkzN/B8rIyGDs2LG0atWKLVu2yK3lTnb27Fmys7Pp3r272aEIR8jKuqyqB2ArkAhsqcw68vIgO9vgwNyDJH8HyM/P56233mLWrFl8/PHHPPTQQzKMsAm+//57goOD8fHxMTsU4QhnzthdnAocAHytr/8AioAdgN2xQnNzDQ/NHUjyN1haWhpjx47F39+frKwsbrrpJrND8lrS5ePZTmO5oFvWeGC0zeupWA4G5RZ2NmpkaFzuQvr8DXLu3Dn++te/EhYWxj//+U9iYmIk8ZtMLvZ6Fq0127ZtY/Lkydx11118tnYtF2vWvKxdfaCZzeNaLLX+di/p+viAv78Do3Zd1Ur+SqnGSqnVSqk91p+XHUKVUh2UUuuVUtuVUllKqf+tzjZdUXJyMgEBAZw6dYrs7Gzuv/9+s0PyeidOnGD//v0EeWkNt6fQWpOVlcXrr79O+/btGTp0KH/88Qdffvkl/9i1izq1a1e4jjeBb8rfADz2mHEBu5Hqdvu8AiRprd9TSr1iff33Mm3OA/+ntd6jlGoBZCilErTWp6u5bdOdOXOGl19+mRUrVhAVFcWQIUPMDklYpaSk0KtXL2pXIjkI16K1ZuvWrcTGxhITE8PFixcJDw8nOjqa4ODgS6+fDR5sGbLhaoZ7VgqGDPHKMk+ofvIfDvS1Pp+N5VrLJclfa73b5vmvSqkcLN/A3Dr5L1u2jKeffpohQ4aQnZ1Nw4YNzQ5J2JAuH/eitebHH38kJiaG2NhYiouLCQ8P59tvv6Vz587lF0xMmgQJCZY7dqvKx8fyeS9V3eR/k9b6NwCt9W9KqRuv1FgpFQzUAfZVc7umOXnyJH/729/44YcfmD17tiQYF5WcnMxTTz1ldhjiCrTWbN68uTTh16xZk/DwcObPn0/Hjh0rVyHXpQtMnWoZqqEqB4D69S2f8+JuwQqTv1IqEct1k7JercqGlFLNga+BMVpruwNxKKXGY7lYj6+vr70mplqwYAETJkzggQceIDs7m2uuucbskIQdhw8f5uTJkzJQngvSWrNx40ZiY2OJjY2lbt26hIeHs2jRIgICAq6uJDoiwvJz4kRL3f6VuoCUspzxT5365+e8VIXJX2td7qSxSqljSqnm1rP+5kBOOe0aAMuA17TWG66wrS+ALwCCgoKufs42gx07doznnnuO7OxsYmNj6dGjh9khiStITk6mX79+1KghxWyuoLi4mA0bNpQm/GuuuYbw8HCWLFmCn5+fMffARERYvgVMmWIZskEpy4GghI+P5aAwZIilq8eLz/hLVLfbJx4YA7xn/RlXtoFSqg6wCJijtY6p5vacSmvN3LlzefHFFxk7dixff/019erVMzssUQHp7zdfcXExaWlpxMTEsGDBAq6//nrCw8NZsWIFd911l2M2GhQECxZYxuqJjrbcuZuba6nj9/e3VPV46cVde5SuxqTISqkbgPlYbqY7CIRrrU8ppYKAp7XWTyilHgG+ArbbfPQxrfXWK607KChIb968+apjq67Dhw/z9NNPc+jQIWbNmkXnzp1Ni0VUntYaX19fkpKSuP32280Ox6sUFRXxww8/EBsby4IFC2jSpAnh4eGEhYVx5513mh2e11BKZWitK/xqU60zf631SeyMmKq13gw8YX3+DVcos3WoMnN50rAhBATA44+XewagtbbUEP/jH0yYMIGFCxfKzFpuZO/evWitue2228wOxSsUFhby/fffExMTw8KFC2nevDlhYWGkpKTIcOUuzjOHd0hPt/T9rVhheW07+NPChTB5sqU+eNIkSz+h1f79+3nyySc5e/YsKSkp+Pn5OTlwUV0lXT4ylpLjFBYWkpqaSmxsLIsWLaJly5aEh4fz/fffy0HXjXjeFbEK5vIkL++yuTyLi4v59NNP6dKlC4MGDSItLU0Sv5tKSkqS/n4HKCgoYNWqVYwfP54WLVowadIk2rZty/r168nIyOCVV16RxO9mqtXn70hX1ecfGVnlet/ievX4uEUL4lq0YObMmdJP7MaKi4u56aabyMjIcMlSYXdz8eJFkpOTiYmJIS4ujltvvZWwsDDCwsJo3bq12eGJcjilz9+lpKfbTfyPYJnN5xyWmxVexnoxwqpGfj7PHzrEC/PmUUMSv1vbtm0b119/vST+arh48SKJiYnExMQQHx9Pu3btCA8PZ/LkybJfPYznJP8pUy6t67WahGUat7rATixjUXQEbGt3ahcWwvvvW8rEhNuSLp+rc+HCBVatWkVsbCxLliyhffv2hIeH8/bbb9OqVYVzYQk35RnJ3zqXp707+2wripX1sY9Lk7+3z+XpKZKTk3n00UfNDsMt5Ofnk5CQQExMDMuWLSMgIICwsDDeffddbr75ZrPDE07gGRd8K5iD8xksY3zfATQH7I696cVzeXqCwsJC1q5dS9++fc0OxWXl5eWxaNEiHnroIZo1a8a//vUvevTowY4dO1izZg0TJkyQxO9FPOPMv5y5PEtMA/4DrMcy7Ghde428eC5PT7B582ZuueUWbrzximMLep3z58+zfPlyYmNjWblyJUFBQYSFhfHJJ5/IZENezjOSfzlzedqqCdyN5W6zSOAv9hp56VyeniA5OVmmbLQ6d+4cy5YtIyYmhlWrVtG1a1fCwsL4z3/+Q1Pp1hRWnpH8qzCWfiHljye95cABfl22jG7dunHDDTcYEppwjuTkZJ5//nmzwzDN77//XprwExMT6d69O+Hh4URGRtKkSROzwxMuyDOSf0CApVKnTNdPDpAMhAI+QCIwD/jWzioK69Qh56ab+OSTT9i0aRMtWrSge/fu9OjRgx49enDnnXfKKJEuKj8/n40bN9K7d2+zQ3Gqs2fPsmTJEmJiYkhJSeHuu+8mLCyMGTNm0LhxY7PDEy7OM27yysmBW265LPkfB8KATKAYuAVLd8+T9tZRrx4cPAhNm1JUVMS2bdtYv349aWlprF+/nuPHj9OtW7fSA0LXrl1p0KBBNf6FwigpKSlMmjSJDRvKHS3cY5w+fbo04aemptKnTx/CwsIYNmwYjRpdNoW28EKVvcnLM5I/wKhR1ZvLc+TIK9b55+TksH79+tIDwo8//kjbtm3p0aNH6QHh1ltvlTFlTPD6669TVFTEu+++a3YoDpGbm0tcXByxsbGsXbuWfv36ER4ezn333SfTh4rLeF/yT0+3jNVzNXN51q8Pa9ZUaYKHixcvkpmZWfrNIC0tjby8vNIDQffu3enSpQv169evejyiSnr27Mlbb73FvfeWO++Q2zl16hSLFy8mNjaWdevW0b9/f8LDwwkNDZVvnOKKvC/5w1WN7VM6l6cBU7odPnz4kq6i7Oxs7rzzztLrBt27d8fX11e+HRjo999/p3nz5hw/fhwfHx+zw6mWEydOsHjxYmJiYtiwYQMDBgwgLCyMoUOHct1115kdnnAT3pn84c8DgAvM5ZmXl8ePP/54ybeDmjVrXnIhuWPHjtSta/fOA1EJy5cv58MPPyQlJcXsUK5KTk4OixYtIjY2lk2bNjFo0CDCw8MZPHgw1157rdnhCTfkfQO7lXChuTx9fHzo2bMnPXv2BCwTxRw4cIC0tDTS0tL45ptv2LVrFx06dLiku6h58+YOi8nTuOOUjceOHWPhwoXExsaSkZFBSEgITz/9NHFxcdJNKJzG8878bbnBXJ5//PEH6enppQeEDRs20KBBg0suJAcEBFCrlucdp43QsWNHPv/8c3r06GF2KFf022+/sXDhQmJiYti6dStDhw4lLCyMkJAQt++uEq7Fe7t93FxxcTG7d+8u7SZKS0vj4MGDBAUFlR4QunfvLjehASdPnqRNmzacPHmS2rVrmx3OZY4cOVKa8LOzswkNDSU8PJyBAwdSr149s8MTHkqSvwfJzc1l48aNpQeETZs20bx580u6itq3b+91N6EtWLCAmTNnsnz5crNDKXXo0CEWLFhAbGwsO3bsYNiwYYSFhTFgwAC5tiOcwnv7/D1Qo0aNCAkJISQkBICioiK2b99OWloaP/zwAx988IFX3oSWlJTkEuP5/PLLLyxYsICYmBh2797N8OHDefXVV7nnnnuoU6eO2eEJYZec+XuInJwcNmzYUFpZlJGRQdu2bS+pLPK0m9DuuOMO5s2bR8eOHZ2+7f379xMbG0tsbCz79u1jxIgRhIeH079/f5fsghLeQ7p9vFxBQUHpTWglB4Tz58+XXjPo0aOHW9+EduTIEQICAjh+/LjTurv27dtHbGwsMTExHDx4kJEjRxIWFkbfvn0l4QuXIclfXObIkSOX3ISWlZVVehNayQHBXW5C+/rrr0uHPHCkPXv2lCb8I0eOMGrUKMLCwujTp49UYAmXJMlfVCg/P7/0JrSSh+1NaN27d6dTp04ueaHy8ccfp0uXLjzzzDOGr3vXrl3ExMQQGxvLsWPHGDVqFOHh4fTq1YuaNWsavj0hjCQXfEWF6tWrV3o9AP68Ca3k20HJTWiBgYGXDFFhyk1oOTmWezaystBnznBfcjJ333CDYfMu//TTT8TExBATE8OpU6e4//77+fTTT+nZs6ckfOGR5MxfXFHJTWi23UUNGjS45EKyQ29CS0+33K29YoXltc2w3drHB6U1DB5suVu7S5dKr1Zrzfbt20u7dM6cOUNYWBhhYWH06NHD68pmheeQbh/hEFprdu/efcl4Rb/88gtBQUGlB4Ru3boZM3uUweM0aa3Jzs4u7dI5d+4cYWFhhIeH07VrV0n4wiM4JfkrpRoD3wGtgQPAA1pruxPhKqUaAD8Bi7TWz1W0bkn+7uP06dNs3Lix9ICwceNGmjVrdsmF5CrfhFZmhNYLwDNYZmM7BdwKvAsMtv2MnRFatdZkZmaWJvwLFy6UJvzg4GC3uLgtRFU4K/l/AJzSWr+nlHoFaKS1/ns5bf8NNLW2l+TvwYqKitixY8clZaY5OTl07dq19IDQtWvX8icisTM3wzngQ+AxwBdYDjwIZGM58yhVvz46NZUfa9QorcMvKioiPDycsLAwgoKCJOELj+as5L8L6Ku1/k0p1RxI1Vq3s9OuM/ASsBIIkuTvfY4fP37ZTWitW7e+5ELybbfdZknMlZyVLQCYDNxvs6wYWFW/Ps81b054eDjh4eF07NhREr7wGs5K/qe11tfbvM7VWjcq06YGlnnUHwXuQZK/wHITWlZW1iXfDs6dO8egjh2JTkmhVmHhFT9/DMuczFuBO8q8V1ynDurQIdSNNzooeiFcl2GlnkqpRKCZnbderWQszwDLtdaHKjr7UkqNB8YD+Pr6VnL1wh3Vrl2bzp0707lzZyZMmADAr7/+yom//53iCk5ICoCHgTFcnvgBatSsCbNnw0svGR22EB6jwuSvtS53YlSl1DGlVHObbp8cO826A72UUs8A1wJ1lFJ/aK1fsbOtL4AvwHLmX9l/hPAMLVq0oIXWUFRUbptiLF8h6wCfldcoL88yh4MQolzVLc6Ox3IC9p71Z1zZBlrrh0ueK6Uew9Ltc1niFwKAM2fKfUsD47B0+SwHrjiaTq7dojMhhFV1C5vfAwYopfYAA6yvUUoFKaW+rG5wwguVVwEERGCpFV4CVDj3VaNGFbUQwqtVK/lrrU9qre/RWt9m/XnKunyz1voJO+2jK3OxV3ixgACwM8vVL8B0LBd4m2HpP7wWmGtvHT4+luk6hRDlklsahWt57DG7i2/B0u2TD/xh83jYXmOty12PEMJCkr9wLTfeaBmr52rr8pWCIUMMGexNCE8myV+4nkmTLF03V8PHx/J5IcQVSfIXrqdLF8sYPVWdZaxkbJ+gCu9vEcLryXj+wjWVDM5m4KieQog/yZm/cF0REbBmDYwcaakAKtsV5ONjWT5ypKWdJH4hKk3O/IVrCwqCBQssM3ZFR1vu3M3NtdTx+/tbqnrk4q4QVSbJX7iHpk1lrB4hDCTdPkII4YUk+QshhBeS5C+EEF5Ikr8QQnghSf5CCOGFJPkLIYQXqtYcvo6klDqOZSRfozQBThi4PqO5enzg+jG6enwgMRrB1eMDc2O8RWtd4c0vLpv8jaaU2lyZSY3N4urxgevH6OrxgcRoBFePD9wjRun2EUIILyTJXwghvJA3Jf8vzA6gAq4eH7h+jK4eH0iMRnD1+MANYvSaPn8hhBB/8qYzfyGEEFYelfyVUuFKqe1KqWKlVLlX2pVSIUqpXUqpvUqpV2yWt1FKbVRK7VFKfaeUqmNwfI2VUqut61+tlGpkp00/pdRWm0e+UmqE9b1opdR+m/c6GBlfZWO0tiuyiSPeZrkr7MMOSqn11r+FLKXU/9q857B9WN7flc37da37ZK91H7W2eW+SdfkupdQgo2KqYnwvKKV2WPdZklLqFpv37P6+TYjxMaXUcZtYnrB5b4z172KPUmqMSfF9YhPbbqXUaZv3nLIPK01r7TEP4E6gHZAKBJXTpiawD2gL1AEygfbW9+YDo63Po4AIg+P7AHjF+vwV4P0K2jcGTgH1ra+jgTAH78NKxQj8Uc5y0/chcDtwm/V5C+A34HpH7sMr/V3ZtHkGiLI+Hw18Z33e3tq+LtDGup6aJsTXz+ZvLaIkviv9vk2I8THgMzufbQz8bP3ZyPq8kbPjK9N+AjDLmfuwKg+POvPXWv+ktd5VQbNgYK/W+met9UXgv8BwpZQC+gOx1nazgREGhzjcut7Krj8MWKG1Pm9wHFdS1RhLuco+1Frv1lrvsT7/FcgBHD3ji92/qzJtbGOPBe6x7rPhwH+11he01vuBvdb1OTU+rXWKzd/aBqClwTFUO8YrGASs1lqf0lrnAquBEJPjexCYZ3AMhvGo5F9JNwOHbF4fti67ATittS4ss9xIN2mtfwOw/ryxgvajufyP55/Wr+WfKKXqGhxfVWKsp5TarJTaUNIthQvuQ6VUMJaztH02ix2xD8v7u7LbxrqPzmDZZ5X5rDPiszUOWGHz2t7v22iVjfF+6+8vVinVqoqfdUZ8WLvM2gDJNoudsQ8rze1m8lJKJQLN7Lz1qtY6rjKrsLNMX2F5lVwpviqupzngDyTYLJ4EHMWSzL4A/g68bVKMvlrrX5VSbYFkpVQ2cNZOO7P34dfAGK11sXWxIfvQ3ubsLCv7b3fo314FKr0NpdQjQBDQx2bxZb9vrfU+e593cIxLgHla6wtKqaexfJPqX8nPOiO+EqOBWK11kc0yZ+zDSnO75K+1vreaqzgMtLJ53RL4Fcs4HNcrpWpZz8pKlhsWn1LqmFKqudb6N2tiyrnCqh4AFmmtC2zW/Zv16QWl1FfAxKrGZ1SM1u4UtNY/K6VSgY7AAlxkHyqlGgDLgNe01hts1m3IPrSjvL8re20OK6VqAQ2xXNOpzGedER9KqXuxHGT7aK0vlCwv5/dtdOKqMEat9UmblzOA920+27fMZ1OdHZ+N0cCztguctA8rzRu7fdKB25SlKqUOll9SvLZckUnB0s8OMAaozDeJqoi3rrcy67+sv9Ca7Er61kcA2wyOr1IxKqUalXSXKKWaAD2BHa6yD62/10XAHK11TJn3HLUP7f5dXSH2MCDZus/igdHWaqA2wG3AJoPiqnR8SqmOwHRgmNY6x2a53d+3wfFVNsbmNi+HAT9ZnycAA62xNgIGcum3ZqfEZ42xHZaLzuttljlrH1ae2VecjXwAI7EcnS8Ax4AE6/IWwHKbdkOA3ViOuq/aLG+L5T/dXiAGqGtwfDcAScAe68/G1uVBwJc27VoDR4AaZT6fDGRjSVjfANc6YB9WGCPQwxpHpvXnOFfah8AjQAGw1ebRwdH70N7fFZYupWHW5/Ws+2SvdR+1tfnsq9bP7QIGO+j/R0XxJVr/35Tss/iKft8mxDgF2G6NJQW4w+azY637di/wuBnxWV+/CbxX5nNO24eVfcgdvkII4YW8sdtHCCG8niR/IYTwQpL8hRDCC0nyF0IILyTJXwghvJAkfyGE8EKS/IUQwgtJ8hdCCC/0/wH1Xy6tV5NiOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "G2 = {1:{2,3,4,5}, 2:{1,3,4}, 3:{1,2}, 4: {1,2,5}, 5:{1,4}}\n",
    "draw_graph(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (470, 31)\n",
      "(1,) 1.0\n",
      "(1, 2) 2.0000000000000004\n",
      "(1, 2, 3) 2.000000000000002\n",
      "(1, 2, 3, 4) 2.999999999999991\n",
      "(1, 2, 3, 4, 5) 2.9999999999999982\n",
      "(1, 2, 3, 5) 2.9999999999999916\n",
      "(1, 2, 4) 2.9999999999999902\n",
      "(1, 2, 4, 5) 3.0000000000000036\n",
      "(1, 2, 5) 2.9999999999999973\n",
      "(1, 3) 2.0000000000000093\n",
      "(1, 3, 4) 2.999999999999992\n",
      "(1, 3, 4, 5) 2.999999999999993\n",
      "(1, 3, 5) 2.9999999999999925\n",
      "(1, 4) 2.0000000000000053\n",
      "(1, 4, 5) 2.0000000000000053\n",
      "(1, 5) 2.000000000000004\n",
      "(2,) 0.9999999999999999\n",
      "(2, 3) 1.9999999999999922\n",
      "(2, 3, 4) 2.999999999999988\n",
      "(2, 3, 4, 5) 2.9999999999999982\n",
      "(2, 3, 5) 2.99999999999999\n",
      "(2, 4) 2.000000000000003\n",
      "(2, 4, 5) 2.0000000000000084\n",
      "(2, 5) 1.9999999999999982\n",
      "(3,) 0.9999999999999999\n",
      "(3, 4) 2.0000000000000004\n",
      "(3, 4, 5) 2.000000000000004\n",
      "(3, 5) 1.9999999999999944\n",
      "(4,) 1.0\n",
      "(4, 5) 1.000000000000019\n",
      "(5,) 1.0000000000000004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     con: array([ 0.00000000e+00,  7.10542736e-15, -1.77635684e-15, -1.33226763e-15,\n",
       "        0.00000000e+00])\n",
       "     fun: -2.9999999999999982\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 861\n",
       "   slack: array([ 0.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "       -4.44089210e-16,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.28785871e-14,  4.88498131e-15,  8.88178420e-16,\n",
       "       -9.32587341e-15,  8.43769499e-15,  1.11022302e-14,  1.99840144e-15,\n",
       "       -5.32907052e-15,  1.37667655e-14, -3.55271368e-15,  1.77635684e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.50990331e-14,  2.22044605e-15,\n",
       "        7.10542736e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.33226763e-14,  5.32907052e-15,\n",
       "        1.33226763e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.02140518e-14,  1.59872116e-14,  3.55271368e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.33226763e-15,\n",
       "        7.10542736e-15,  7.54951657e-15, -7.10542736e-15, -5.77315973e-15,\n",
       "       -1.24344979e-14, -6.21724894e-15,  1.64313008e-14,  8.88178420e-15,\n",
       "        1.46549439e-14,  1.00000000e+00,  9.99200722e-15,  6.88338275e-15,\n",
       "        9.76996262e-15,  7.99360578e-15,  1.42108547e-14,  1.24344979e-14,\n",
       "        8.43769499e-15,  1.00000000e+00,  1.15463195e-14,  7.99360578e-15,\n",
       "        4.88498131e-15,  1.11022302e-14,  2.30926389e-14,  1.11022302e-14,\n",
       "        7.10542736e-15,  1.00000000e+00,  8.88178420e-16,  6.21724894e-15,\n",
       "        1.00000000e+00,  1.00000000e+00, -8.88178420e-16, -6.21724894e-15,\n",
       "        1.00000000e+00,  1.00000000e+00, -7.10542736e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  3.10862447e-15,  3.10862447e-15,\n",
       "        1.00000000e+00,  1.00000000e+00, -1.77635684e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00, -3.55271368e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.19904087e-14,  1.00000000e+00,  6.66133815e-15,\n",
       "        7.99360578e-15, -5.32907052e-15,  8.88178420e-16,  1.00000000e+00,\n",
       "        6.21724894e-15,  5.32907052e-15,  5.77315973e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.02140518e-14,  0.00000000e+00,  8.43769499e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00, -4.44089210e-16, -5.77315973e-15,\n",
       "        1.00000000e+00,  1.00000000e+00, -6.66133815e-15, -8.88178420e-16,\n",
       "        1.00000000e+00, -5.32907052e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.22044605e-15,  1.77635684e-15,\n",
       "        1.00000000e+00,  3.55271368e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  2.88657986e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.19904087e-14,  2.00000000e+00,  1.33226763e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00, -1.33226763e-14,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00, -8.43769499e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        5.77315973e-15,  1.00000000e+00,  6.21724894e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -4.44089210e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  3.99680289e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.24344979e-14,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.22044605e-14,  2.17603713e-14,\n",
       "        2.08721929e-14,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.77635684e-14,  2.04281037e-14,\n",
       "        1.13242749e-14,  1.73194792e-14,  3.55271368e-14,  1.73194792e-14,\n",
       "        8.88178420e-16,  1.00000000e+00,  1.00000000e+00, -8.88178420e-16,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  1.00000000e+00,  3.10862447e-15,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.82076576e-14,  1.00000000e+00,\n",
       "        4.44089210e-16,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.33226763e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        8.88178420e-15,  1.00000000e+00,  1.00000000e+00,  1.82076576e-14,\n",
       "        2.00000000e+00,  0.00000000e+00,  1.00000000e+00,  1.50990331e-14,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.86517468e-14,  1.02140518e-14,  1.00000000e+00,  1.33226763e-14,\n",
       "        1.33226763e-14,  1.64313008e-14,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.90958360e-14,  1.00000000e+00,  1.33226763e-15,  1.66533454e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        4.88498131e-15, -8.43769499e-15, -4.44089210e-16,  1.23234756e-14,\n",
       "        1.28785871e-14, -3.10862447e-15,  6.43929354e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  6.66133815e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        8.43769499e-15,  3.99680289e-15,  1.15463195e-14,  1.00000000e+00,\n",
       "        1.46549439e-14,  5.32907052e-15,  1.00000000e+00,  1.73194792e-14,\n",
       "        1.00000000e+00,  1.11022302e-16,  1.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  7.54951657e-15,  1.24344979e-14,  5.66213743e-15,\n",
       "        4.66293670e-15, -3.10862447e-15,  1.06581410e-14,  2.10942375e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  7.54951657e-15,\n",
       "        2.55351296e-15,  6.66133815e-16,  1.00000000e+00,  4.88498131e-15,\n",
       "       -1.88737914e-15, -3.10862447e-15,  3.99680289e-15,  1.33226763e-14,\n",
       "        2.88657986e-15,  1.02140518e-14,  1.00000000e+00,  1.00000000e+00,\n",
       "       -4.88498131e-15,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "       -6.66133815e-15,  1.00000000e+00,  2.00000000e+00,  8.88178420e-15,\n",
       "        1.00000000e+00,  8.43769499e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.77635684e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  8.88178420e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.02140518e-14,  2.00000000e+00,  5.32907052e-15,  1.00000000e+00,\n",
       "        1.50990331e-14,  1.55431223e-14,  8.88178420e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.37667655e-14,  1.00000000e+00,  1.02140518e-14,\n",
       "        1.01030295e-14,  1.06581410e-14, -4.88498131e-15,  4.21884749e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  8.43769499e-15,\n",
       "        1.00000000e+00,  3.55271368e-15,  2.66453526e-15,  1.00000000e+00,\n",
       "        8.43769499e-15,  1.00000000e+00,  1.11022302e-16,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -4.44089210e-16,  1.50990331e-14,\n",
       "        5.88418203e-15,  3.55271368e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.55431223e-14,  1.00000000e+00,  9.54791801e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  9.10382880e-15,\n",
       "        1.00000000e+00,  0.00000000e+00,  1.90958360e-14,  1.00000000e+00,\n",
       "        1.86517468e-14, -4.44089210e-16])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1., 2., 2., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 2., 2., 2., 1.,\n",
       "       2., 3., 3., 3., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_entropy(G1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (470, 31)\n",
      "(1,) 0.9999999999999998\n",
      "(1, 2) 1.9999999999999891\n",
      "(1, 2, 3) 1.9999999999999978\n",
      "(1, 2, 3, 4) 2.999999999999993\n",
      "(1, 2, 3, 4, 5) 2.9999999999999933\n",
      "(1, 2, 3, 5) 2.999999999999994\n",
      "(1, 2, 4) 2.999999999999994\n",
      "(1, 2, 4, 5) 2.9999999999999827\n",
      "(1, 2, 5) 2.999999999999996\n",
      "(1, 3) 1.9999999999999882\n",
      "(1, 3, 4) 2.9999999999999907\n",
      "(1, 3, 4, 5) 2.99999999999999\n",
      "(1, 3, 5) 2.9999999999999822\n",
      "(1, 4) 1.9999999999999953\n",
      "(1, 4, 5) 1.999999999999999\n",
      "(1, 5) 1.9999999999999873\n",
      "(2,) 1.0\n",
      "(2, 3) 1.999999999999994\n",
      "(2, 3, 4) 2.9999999999999893\n",
      "(2, 3, 4, 5) 2.9999999999999933\n",
      "(2, 3, 5) 2.9999999999999876\n",
      "(2, 4) 2.0000000000000004\n",
      "(2, 4, 5) 2.0000000000000067\n",
      "(2, 5) 2.000000000000002\n",
      "(3,) 0.9999999999999999\n",
      "(3, 4) 1.9999999999999971\n",
      "(3, 4, 5) 2.000000000000001\n",
      "(3, 5) 1.9999999999999962\n",
      "(4,) 0.9999999999999998\n",
      "(4, 5) 1.0000000000000038\n",
      "(5,) 0.9999999999999984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     con: array([ 0.00000000e+00, -2.22044605e-15, -8.65973959e-15,  1.33226763e-14,\n",
       "       -3.55271368e-15])\n",
       "     fun: -2.9999999999999933\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 830\n",
       "   slack: array([ 2.22044605e-16,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.06581410e-14,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  6.21724894e-15,  2.37587727e-14,  5.99520433e-15,\n",
       "        1.13242749e-14,  6.21724894e-15,  1.08801856e-14,  1.37667655e-14,\n",
       "        4.21884749e-15,  4.66293670e-15,  1.08801856e-14,  8.65973959e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -8.88178420e-15,  5.55111512e-15,\n",
       "       -1.88737914e-14,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -4.44089210e-15,  1.31006317e-14,\n",
       "       -4.88498131e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00, -4.88498131e-15,  1.02140518e-14, -8.43769499e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  9.10382880e-15,\n",
       "       -1.77635684e-15,  1.06581410e-14,  9.54791801e-15,  7.32747196e-15,\n",
       "        6.21724894e-15, -2.22044605e-15,  4.44089210e-16,  3.55271368e-15,\n",
       "       -8.88178420e-15,  1.00000000e+00,  3.77475828e-15,  6.66133815e-16,\n",
       "        3.55271368e-15, -2.22044605e-15,  5.32907052e-15,  1.11022302e-14,\n",
       "        6.21724894e-15,  1.00000000e+00,  2.10942375e-15,  5.32907052e-15,\n",
       "        0.00000000e+00,  4.66293670e-15,  8.21565038e-15,  2.66453526e-15,\n",
       "        4.44089210e-16,  1.00000000e+00, -8.88178420e-16, -1.19904087e-14,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.22044605e-15, -1.77635684e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  3.55271368e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  3.55271368e-15,  3.10862447e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  6.21724894e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  3.55271368e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  3.55271368e-15,  1.00000000e+00, -4.44089210e-16,\n",
       "       -4.44089210e-16,  1.06581410e-14, -2.66453526e-15,  1.00000000e+00,\n",
       "        2.66453526e-15,  3.55271368e-15,  1.11022302e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        3.99680289e-15,  0.00000000e+00,  5.77315973e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00, -1.28785871e-14, -2.22044605e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  8.43769499e-15,  1.15463195e-14,\n",
       "        1.00000000e+00,  1.19904087e-14,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  6.66133815e-15,  6.21724894e-15,\n",
       "        1.00000000e+00,  4.88498131e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  5.10702591e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        5.55111512e-15,  2.00000000e+00, -1.11022302e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.48769885e-14,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.68753900e-14,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        1.50990331e-14,  1.00000000e+00, -1.33226763e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.53130850e-14,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.77635684e-14,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.86517468e-14,  2.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -6.66133815e-15, -2.44249065e-15,\n",
       "       -6.66133815e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -5.32907052e-15, -5.55111512e-16,\n",
       "        2.22044605e-15, -2.66453526e-15,  2.22044605e-15,  4.44089210e-15,\n",
       "       -8.88178420e-16,  1.00000000e+00,  1.00000000e+00,  4.21884749e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  1.00000000e+00,  4.21884749e-15,\n",
       "        1.00000000e+00,  2.00000000e+00,  4.88498131e-15,  1.00000000e+00,\n",
       "        7.54951657e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "        4.44089210e-15,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "       -2.66453526e-15,  1.00000000e+00,  1.00000000e+00, -2.66453526e-15,\n",
       "        2.00000000e+00,  3.55271368e-15,  1.00000000e+00,  1.77635684e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.77635684e-15,  1.95399252e-14,  1.00000000e+00,  4.44089210e-15,\n",
       "        2.22044605e-15,  6.66133815e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        4.44089210e-16,  1.00000000e+00,  1.15463195e-14,  1.62092562e-14,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.68753900e-14,  1.88737914e-14,  1.99840144e-14,  8.99280650e-15,\n",
       "        6.43929354e-15,  6.43929354e-15,  6.88338275e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00, -8.65973959e-15,  1.00000000e+00,\n",
       "        2.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.28785871e-14, -4.88498131e-15,  5.10702591e-15,  1.00000000e+00,\n",
       "        0.00000000e+00,  2.66453526e-15,  1.00000000e+00, -6.21724894e-15,\n",
       "        1.00000000e+00,  0.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "        2.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  5.99520433e-15,  7.99360578e-15,  7.54951657e-15,\n",
       "        8.65973959e-15, -6.66133815e-16, -3.10862447e-15, -3.77475828e-15,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  5.32907052e-15,\n",
       "        7.32747196e-15,  8.65973959e-15,  1.00000000e+00,  1.77635684e-15,\n",
       "        1.66533454e-15,  2.66453526e-15,  4.44089210e-15,  4.44089210e-15,\n",
       "        4.88498131e-15,  3.99680289e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        2.66453526e-15,  1.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "       -2.22044605e-16,  1.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n",
       "        1.00000000e+00,  5.77315973e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00, -1.33226763e-15,  1.00000000e+00,  2.00000000e+00,\n",
       "        1.00000000e+00, -8.88178420e-16,  1.00000000e+00,  1.00000000e+00,\n",
       "       -8.88178420e-16,  2.00000000e+00,  6.21724894e-15,  1.00000000e+00,\n",
       "        1.11022302e-14,  7.99360578e-15,  8.21565038e-15,  1.00000000e+00,\n",
       "        1.00000000e+00, -2.22044605e-15,  1.00000000e+00,  4.44089210e-15,\n",
       "        1.32116540e-14,  1.06581410e-14,  9.99200722e-15,  1.11022302e-14,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.46549439e-14,\n",
       "        1.00000000e+00,  1.13242749e-14,  1.24344979e-14,  1.00000000e+00,\n",
       "        6.66133815e-16,  1.00000000e+00,  1.11022302e-16,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  2.44249065e-15,  2.66453526e-15,\n",
       "        2.10942375e-15,  3.77475828e-15,  1.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  1.00000000e+00,  4.66293670e-15,  1.00000000e+00,\n",
       "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  8.88178420e-16,\n",
       "        1.00000000e+00,  2.22044605e-16,  3.99680289e-15,  1.00000000e+00,\n",
       "        5.32907052e-15,  1.55431223e-15])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([1., 2., 2., 3., 3., 3., 3., 3., 3., 2., 3., 3., 3., 2., 2., 2., 1.,\n",
       "       2., 3., 3., 3., 2., 2., 2., 1., 2., 2., 2., 1., 1., 1.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_entropy(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (470, 31)\n",
      "(1,) 1.0\n",
      "(1, 2) 2.0000000000000004\n",
      "(1, 2, 3) 2.000000000000002\n",
      "(1, 2, 3, 4) 2.999999999999991\n",
      "(1, 2, 3, 4, 5) 2.9999999999999982\n",
      "(1, 2, 3, 5) 2.9999999999999916\n",
      "(1, 2, 4) 2.9999999999999902\n",
      "(1, 2, 4, 5) 3.0000000000000036\n",
      "(1, 2, 5) 2.9999999999999973\n",
      "(1, 3) 2.0000000000000093\n",
      "(1, 3, 4) 2.999999999999992\n",
      "(1, 3, 4, 5) 2.999999999999993\n",
      "(1, 3, 5) 2.9999999999999925\n",
      "(1, 4) 2.0000000000000053\n",
      "(1, 4, 5) 2.0000000000000053\n",
      "(1, 5) 2.000000000000004\n",
      "(2,) 0.9999999999999999\n",
      "(2, 3) 1.9999999999999922\n",
      "(2, 3, 4) 2.999999999999988\n",
      "(2, 3, 4, 5) 2.9999999999999982\n",
      "(2, 3, 5) 2.99999999999999\n",
      "(2, 4) 2.000000000000003\n",
      "(2, 4, 5) 2.0000000000000084\n",
      "(2, 5) 1.9999999999999982\n",
      "(3,) 0.9999999999999999\n",
      "(3, 4) 2.0000000000000004\n",
      "(3, 4, 5) 2.000000000000004\n",
      "(3, 5) 1.9999999999999944\n",
      "(4,) 1.0\n",
      "(4, 5) 1.000000000000019\n",
      "(5,) 1.0000000000000004\n",
      "[[ 1.  0.  0. ...  0.  0.  0.]\n",
      " [ 1. -1.  0. ...  0.  0.  0.]\n",
      " [ 1.  0. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ... -1.  1. -1.]\n",
      " [ 0.  0.  0. ...  0. -1.  1.]\n",
      " [ 0.  0.  0. ...  0.  0.  1.]] (470, 31)\n",
      "(1,) 0.9999999999999998\n",
      "(1, 2) 1.9999999999999891\n",
      "(1, 2, 3) 1.9999999999999978\n",
      "(1, 2, 3, 4) 2.999999999999993\n",
      "(1, 2, 3, 4, 5) 2.9999999999999933\n",
      "(1, 2, 3, 5) 2.999999999999994\n",
      "(1, 2, 4) 2.999999999999994\n",
      "(1, 2, 4, 5) 2.9999999999999827\n",
      "(1, 2, 5) 2.999999999999996\n",
      "(1, 3) 1.9999999999999882\n",
      "(1, 3, 4) 2.9999999999999907\n",
      "(1, 3, 4, 5) 2.99999999999999\n",
      "(1, 3, 5) 2.9999999999999822\n",
      "(1, 4) 1.9999999999999953\n",
      "(1, 4, 5) 1.999999999999999\n",
      "(1, 5) 1.9999999999999873\n",
      "(2,) 1.0\n",
      "(2, 3) 1.999999999999994\n",
      "(2, 3, 4) 2.9999999999999893\n",
      "(2, 3, 4, 5) 2.9999999999999933\n",
      "(2, 3, 5) 2.9999999999999876\n",
      "(2, 4) 2.0000000000000004\n",
      "(2, 4, 5) 2.0000000000000067\n",
      "(2, 5) 2.000000000000002\n",
      "(3,) 0.9999999999999999\n",
      "(3, 4) 1.9999999999999971\n",
      "(3, 4, 5) 2.000000000000001\n",
      "(3, 5) 1.9999999999999962\n",
      "(4,) 0.9999999999999998\n",
      "(4, 5) 1.0000000000000038\n",
      "(5,) 0.9999999999999984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_identical_entropy(G1,G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
